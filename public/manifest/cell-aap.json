{
  "name": "cell-AAP",
  "display_name": "cell-AAP",
  "visibility": "public",
  "icon": "",
  "categories": [],
  "schema_version": "0.1.0",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "cell-AAP.run",
        "title": "Inference GUI",
        "python_name": "cell_AAP.napari.main:create_cellAAP_widget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "cell-AAP.batch",
        "title": "Batch Inference GUI",
        "python_name": "cell_AAP.napari.main:create_batch_widget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": null,
    "writers": null,
    "widgets": [
      {
        "command": "cell-AAP.run",
        "display_name": "Inference GUI",
        "autogenerate": false
      },
      {
        "command": "cell-AAP.batch",
        "display_name": "Batch Inference GUI",
        "autogenerate": false
      }
    ],
    "sample_data": null,
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.2",
    "name": "cell-AAP",
    "version": "0.0.9",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": null,
    "description": "# Cellular Annotation & Perception Pipeline\n\n![](https://github.com/anishjv/cell-AAP/blob/main/images/figure2.png?raw=true)\n![](https://github.com/anishjv/cell-AAP/blob/main/images/rpe1_u2os.png?raw=true)\n\n\n\n\nUtilities for the semi-automated generation of instance segmentation annotations to be used for neural network training. Utilities are built ontop of [UMAP](https://github.com/lmcinnes/umap), [HDBSCAN](https://arxiv.org/abs/1911.02282) and a finetuned encoder version of FAIR's [Segment Anything Model](https://github.com/facebookresearch/segment-anything/tree/main?tab=readme-ov-file) developed by Computational Cell Analytics for the project [micro-sam](https://github.com/computational-cell-analytics/micro-sam/tree/master/micro_sam/sam_annotator). In addition to providing utilies for annotation building, we train networks using FAIR's [detectron2](https://github.com/facebookresearch/detectron2) to \n1. Demonstrate the efficacy of our utilities. \n2. Be used for microscopy annotation of supported cell lines \n\nCell-line specific models currently include:\n1. HeLa\n2. U2OS\n\nModels have demonstrated performance efficacy on:\n1. HT1080 (HeLa model)\n2. RPE1 (U2OS model)\n\nWe've also developed a napari application for the usage of these pre-trained networks.\n\n\n# Installation \nWe highly recommend installing cell-AAP in a clean conda environment. To do so you must have [miniconda](https://docs.anaconda.com/free/miniconda/#quick-command-line-install) or [anaconda](https://docs.anaconda.com/free/anaconda/) installed.\n\nIf a conda distribution has been installed:\n\n1. Create and activate a clean environment \n\n        conda create -n cell-aap-env python=3.11.0\n        conda activate cell-app-env\n\n2. Within this environment install pip\n\n        conda install pip\n\n3. Then install cell-AAP from PyPi\n\n        pip install cell-AAP --upgrade\n\n4. Finally detectron2 must be built from source, atop cell-AAP\n    \n        #For MacOS\n        CC=clang CXX=clang++ ARCHFLAGS=\"-arch arm64\" python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n\n        #For other operating systems \n        python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n\n\n\n# Napari Plugin Usage\n\n1. To open napari simply type \"napari\" into the command line, ensure that you are working the correct environment\n2. To instantiate the plugin navigate to the \"Plugins\" menu and select \"cell-AAP\"\n3. You should now see the Plugin, where you can select an image, display it, and run inference on it. \n\n\n# Configs Best Practices\n\nIf running inference on large volumes of data, i.e. timeseries data >= 300 MB in size, we recommend to proceed in the following manner. \n\n1. Assemble a small, < 100 MB, substack of your data using python or a program like [ImageJ](https://imagej.net/ij/download.html)\n2. Use this substack to find the optimal parameters for your data, (Number of Cells, Network confidence threshold)\n3. Run Inference over the volume using the discovered optimal parameters\n\n\n# Interpreting Results \n\nOnce inference is complete the following colors indicate class prediction\n- Red: Non-mitotic\n- Blue: Mitotic\n\nFor analysis purposes, masks in the semantic and instance segmentations have the following value mapping:\nSemantic\n- 1: Non-mitotic\n- 100: Mitotic\n\nInstance\n- $2x$: Non-mitotic\n- $2x-1$: Mitotic\n\n\n\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Anish Virdi",
    "author_email": null,
    "maintainer": null,
    "maintainer_email": null,
    "license": null,
    "classifier": [
      "Framework :: napari",
      "Programming Language :: Python :: 3"
    ],
    "requires_dist": [
      "napari[all]>=0.4.19",
      "numpy==1.26.4",
      "opencv-python>=4.9.0",
      "tifffile>=2024.2.12",
      "torch>=2.3.1",
      "torchvision>=0.18.1",
      "scikit-image>=0.22.0",
      "qtpy>=2.4.1",
      "pillow>=10.3.0",
      "scipy>=1.3.0",
      "timm>=1.0.7",
      "pandas>=2.2.2",
      "superqt>=0.6.3",
      "btrack>=0.6.5",
      "seaborn>=0.13.2",
      "openpyxl>=3.1.4",
      "joblib>=1.0",
      "scikit-learn>=0.22",
      "cython<3,>=0.27"
    ],
    "requires_python": "<3.13,>=3.11",
    "requires_external": null,
    "project_url": null,
    "provides_extra": null,
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}