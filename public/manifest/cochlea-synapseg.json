{
  "name": "cochlea-synapseg",
  "display_name": "Cochlea SynapSeg",
  "visibility": "public",
  "icon": "",
  "categories": [
    "Annotation",
    "Segmentation",
    "Acquisition"
  ],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "cochlea-synapseg.get_reader",
        "title": "Open data with Cochlea SynapSeg",
        "python_name": "napari_cochlea_synapse_seg._reader:napari_get_reader",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "cochlea-synapseg.write_multiple",
        "title": "Save multi-layer data with Cochlea SynapSeg",
        "python_name": "napari_cochlea_synapse_seg._writer:write_multiple",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "cochlea-synapseg.write_single_image",
        "title": "Save image data with Cochlea SynapSeg",
        "python_name": "napari_cochlea_synapse_seg._writer:write_single_image",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "cochlea-synapseg.make_sample_data",
        "title": "Load sample data from Cochlea SynapSeg",
        "python_name": "napari_cochlea_synapse_seg._sample_data:make_sample_data",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "cochlea-synapseg.make_gtwidget",
        "title": "Make GTWidget",
        "python_name": "napari_cochlea_synapse_seg:GTWidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": [
      {
        "command": "cochlea-synapseg.get_reader",
        "filename_patterns": [
          "*.zarr",
          "*.xml",
          "*.csv",
          "*.xls",
          "*.XLS"
        ],
        "accepts_directories": true
      }
    ],
    "writers": [
      {
        "command": "cochlea-synapseg.write_multiple",
        "layer_types": [
          "image*",
          "labels*"
        ],
        "filename_extensions": [],
        "display_name": ""
      },
      {
        "command": "cochlea-synapseg.write_single_image",
        "layer_types": [
          "image"
        ],
        "filename_extensions": [
          ".npy"
        ],
        "display_name": ""
      }
    ],
    "widgets": [
      {
        "command": "cochlea-synapseg.make_gtwidget",
        "display_name": "SynapSeg - Ground Truth Widget",
        "autogenerate": false
      }
    ],
    "sample_data": [
      {
        "command": "cochlea-synapseg.make_sample_data",
        "key": "unique_id.1",
        "display_name": "Cochlea SynapSeg"
      }
    ],
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "cochlea-synapseg",
    "version": "0.0.1",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "A plugin to segment cochlear ribbon synapses automatically, as well as edit and adjust",
    "description": "# cochlea-synapseg\n\n[![License BSD-3](https://img.shields.io/pypi/l/cochlea-synapseg.svg?color=green)](https://github.com/ucsdmanorlab/cochlea-synapseg/raw/main/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/cochlea-synapseg.svg?color=green)](https://pypi.org/project/cochlea-synapseg)\n[![Python Version](https://img.shields.io/pypi/pyversions/cochlea-synapseg.svg?color=green)](https://python.org)\n[![tests](https://github.com/ucsdmanorlab/cochlea-synapseg/workflows/tests/badge.svg)](https://github.com/ucsdmanorlab/cochlea-synapseg/actions)\n[![codecov](https://codecov.io/gh/ucsdmanorlab/cochlea-synapseg/branch/main/graph/badge.svg)](https://codecov.io/gh/ucsdmanorlab/cochlea-synapseg)\n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/cochlea-synapseg)](https://napari-hub.org/plugins/cochlea-synapseg)\n\nA plugin to segment cochlear ribbon synapses. \n\nMore is in the works, but for now it includes tools to more quickly generate ground truth ribbon segmentation (Plugins > SynapSeg - Ground Truth Widget).\n\n----------------------------------\n\nThis [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.\n\n<!--\nDon't miss the full getting started guide to set up your new package:\nhttps://github.com/napari/cookiecutter-napari-plugin#getting-started\n\nand review the napari docs for plugin developers:\nhttps://napari.org/stable/plugins/index.html\n-->\n\n## Installation\n\nYou can install `cochlea-synapseg` (receommended: in a new conda environment with up-to-date napari) via [pip]:\n\n    python -m pip install cochlea-synapseg\n\n## Usage\n\nAfter successfull installation, you can find the plugin next time you launch napari (Plugins > SynapSeg - Ground Truth Widget).\n\nThe ground truth widget is divided into multiple sections, for \"quick use\", be sure to check the settings denoted with asterisks:\n\n### Image Tools\n\n![image_tools](https://github.com/user-attachments/assets/323984ad-2cd3-4816-8ee5-e8b3f5063bc0)\n\n\\***1. Image Layer Selection** - use the dropdown to select the name of your image layer (here, the layer that contains the ribbon stain)\n\n(First load a 3D image using one of napari's native readers, or using the Cochlea-Synapseg .zarr reader (reads a .zarr with '3d/raw' and '3d/labeled').)\n\n\\***2. Refresh Image Layer Selection** - update the list of available image layers in #1\n\n**3. Pixel size information** - (in microns), used for some point readers to successfully convert real units to pixel coordinates. Can be left as 1 if this functionality is not needed.\n\n**4. Split channels** - splits multiple channels into separate image layers (useful for FIJI-saved .tif images)\n\n### Points Tools & Points to Labels\n\n![points_tools](https://github.com/user-attachments/assets/6b271d5c-51c1-4ca4-b3c0-683dddd69dc8)\n\n**5. Points Layer Selection and Refresh** - use the dropdown to select an existing points layer, use the refresh button to update the list (or skip to #8 if not loading in existing points)\n\n**6. Real -> Pixel Units** - if you've loaded some points were saved in real units, make sure the pixel size information above in #3 is correct, then click \"real -> pixel units\"\n\n**7. Channel Adjustment** - some points (like ImageJ/FIJI rois or CellCounter points), show up in the wrong z plane because their \"slice\" coordinates are a combination of both slice and channel info. If this happens, set the number of channels (in the original image, where the ROIs were created!), and then click \"chan -> z convert\". Z coordinates of the points layer will be divided by the number of channels specified. \n\n\\***8. New Points Layer** - if starting annotation from scratch, click to create a new points layer. #5 should automatically select this new layer. \n\n\\***9. Rotate to XY and \\*10. Auto-adjust Z** - these convenient functions allow you to quickly annotate points in Napari's 3D view. Simply click \"Rotate to XY before adding new points. These points will now have the correct XY position but will have missing Z information. (Rotate out of XY to confirm.) Click \"Auto-adjust z\" and the z will automatically adjust to the brightest point. \n\n**11. Manually Edit Z** - useful for overlapping points, can be used to manually edit the z position of ONLY selected points. Use the +/- arrow keys for single z steps type in a number to move a larger amount. \n\n**12. Snap too Max** - will automatically adjust all points to their local max (search radius defined in pixels in Advanced Settings -> snap to max rad). Useful for adjusting quickly dropped points, but proceed with caution if you have close-together points. \n\n\\***13. Points to Labels** - the key functionality of the module, creates a label layer by performing a local segmentation on all points.\n\n**14. Advanced Settings** - adjust settings for the points to labels function to optimize local segmentation and watershed separation of points. \n\n### Labels Tools\n\n![labels_tools](https://github.com/user-attachments/assets/6ef20ff6-61e2-4337-a177-8f957a67fb39)\n\n**15. Lables Layer Selection and Refresh** - use the dropdown to select an existing labels layer, use the refresh button to update the list\n\n**16. Make Labels Editable** - zarrs and other file formats tend to load in as dask arrays, which don't allow editing. Checking this box will make the labels layer editable by converting to a numpy array (will load the layer into memory, so be careful if dealing with large images!). This will allow you to edit the labels layer with tools like the paintbrush and eraser. Automatically enables if merging or removing labels is requested (see #17 and #19)\n\n\\***17. Remove a Label** - use the labels layer eyedropper tool to identify the ID of an unwanted label, then type in the box and click \"Remove label\"\n\n**18. Max Label Display** - shows the current maximum label ID. If you're painting labels by hand and need a new label ID, increment above this number. Use the refresh button to the right to get an up-to-date number if you've made changes to your label layer.\n\n\\***19. Merge labels** - if you have an existing labels layer, and then create new labels (e.g. from the points to labels function), select the layer you'd like to merge into your existing labels layer (i.e. box 15 and 19a should be different from one another!), and then click \"merge labels\". This function will automatically ensure overlapping label IDs are not used. \n\n**20. Labels to Points** - if wanted, you can take all your existing labels and convert them to a points layer based on their centroids. This may be helpful for quickly generating better labels using the points tools above. \n\n### Save to Zarr\n\n![save_zarr](https://github.com/user-attachments/assets/1d824f49-012f-4fac-8fa1-64d7d319cd34)\n\nFunctionality to save to .zarr format. Saves image as '3d/raw' and labels as '3d/labeled'. Used for later auto-segmentation of ribbons (not live in this plugin yet, but coming soon!). \n\n\\***21. File Path** - the directory in which to save the zarr; use the folder icon to search for an existing directory\n\n\\***22. File Name** - the zarr name to save to; use the magnifying glass icon to select an existing .zarr\n\n**23. From Source** - set the file path and name to where the image layer was loaded from. (Caution: if you loaded a zarr, this will result in the zarr being overwritten!)\n\n\\***24. Save 3D Only (recommended)** - saves the image and labels layers (selected in #1 and #15) in the specified .zarr, as 3d/raw and 3d/labeled, respectively. A reader is included with this plugin for this format as well. \n\n**25. Save 2D and 3D** - (not recommended) to be used in the future if 2D models are to be run on the data, saves both the 3D stacks as in 24, and then individual 2D slices for each z in 2d/raw/[z] and 2d/labeled/[z]\n\n\n\n## Contributing\n\nContributions are very welcome. Tests can be run with [tox], please ensure\nthe coverage at least stays the same before you submit a pull request.\n\n## License\n\nDistributed under the terms of the [BSD-3] license,\n\"cochlea-synapseg\" is free and open source software\n\n## Issues\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n[napari]: https://github.com/napari/napari\n[Cookiecutter]: https://github.com/audreyr/cookiecutter\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause\n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt\n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt\n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt\n[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin\n\n[napari]: https://github.com/napari/napari\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Cayla Miller",
    "author_email": "cayla@ucsd.edu",
    "maintainer": null,
    "maintainer_email": null,
    "license": "\nCopyright (c) 2024, Cayla Miller\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "classifier": [
      "Development Status :: 2 - Pre-Alpha",
      "Framework :: napari",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.12",
      "Topic :: Scientific/Engineering :: Image Processing"
    ],
    "requires_dist": [
      "numpy",
      "qtpy",
      "scikit-image",
      "scipy",
      "zarr",
      "tox; extra == \"testing\"",
      "pytest; extra == \"testing\"",
      "pytest-cov; extra == \"testing\"",
      "pytest-qt; extra == \"testing\"",
      "napari; extra == \"testing\"",
      "pyqt5; extra == \"testing\""
    ],
    "requires_python": ">=3.9",
    "requires_external": null,
    "project_url": null,
    "provides_extra": [
      "testing"
    ],
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}