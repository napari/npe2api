{
  "name": "napari-kld",
  "display_name": "Kernel Learning Deconvolution",
  "visibility": "public",
  "icon": "",
  "categories": [
    "Image Processing"
  ],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "napari-kld.get_reader",
        "title": "Open data with Kernel Learning Deconvolution",
        "python_name": "napari_kld._reader:napari_get_reader",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.write_multiple",
        "title": "Save multi-layer data with Kernel Learning Deconvolution",
        "python_name": "napari_kld._writer:write_multiple",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.write_single_image",
        "title": "Save image data with Kernel Learning Deconvolution",
        "python_name": "napari_kld._writer:write_single_image",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.make_sample_data",
        "title": "Load sample data from Kernel Learning Deconvolution",
        "python_name": "napari_kld._sample_data:make_sample_data",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.rldwidget",
        "title": "RL Deconvolution",
        "python_name": "napari_kld:RLDwidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.kldwidget",
        "title": "KL Deconvolution",
        "python_name": "napari_kld:KLDwidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": [
      {
        "command": "napari-kld.get_reader",
        "filename_patterns": [
          "*.npy"
        ],
        "accepts_directories": false
      }
    ],
    "writers": [
      {
        "command": "napari-kld.write_multiple",
        "layer_types": [
          "image*",
          "labels*"
        ],
        "filename_extensions": [],
        "display_name": ""
      },
      {
        "command": "napari-kld.write_single_image",
        "layer_types": [
          "image"
        ],
        "filename_extensions": [
          ".npy"
        ],
        "display_name": ""
      }
    ],
    "widgets": [
      {
        "command": "napari-kld.rldwidget",
        "display_name": "RL Deconvolution",
        "autogenerate": false
      },
      {
        "command": "napari-kld.kldwidget",
        "display_name": "KL Deconvolution",
        "autogenerate": false
      }
    ],
    "sample_data": [
      {
        "command": "napari-kld.make_sample_data",
        "key": "unique_id.1",
        "display_name": "Kernel Learning Deconvolution"
      }
    ],
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "napari-kld",
    "version": "1.1.0",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "Kernel learning deconvolution (KLD) is a rapid deconvolution algorithm for fluorescence microscopic image, which learns the forward and backward kernels in Richardson-Lucy Deconvolution (KLD) from paired low-/high-resolution images. ",
    "description": "# napari-kld\n\n[![License](https://img.shields.io/pypi/l/napari-kld.svg?color=green)](https://github.com/qiqi-lu/napari-kld/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/napari-kld.svg?color=green)](https://pypi.org/project/napari-kld)\n[![Python Version](https://img.shields.io/pypi/pyversions/napari-kld.svg?color=green)](https://python.org)\n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-kld)](https://napari-hub.org/plugins/napari-kld)\n\n`napari-kld` is a `napari` plugin that implements kernel learning deconvolution algrotihm.\n\n## **Kernel Learning Deconvolution (KLD)**\n\nKLD is a rapid deconvolution algorithm for fluorescence microscopic image, which learns the forward and backward kernels in Richardson-Lucy Deconvolution (RLD) from paired low-resolution (LR) and high-resolution (HR) images.\n\nIt only requires **one sample** to training the model, and **two iterations** to achieve a superior deconvolution performance compared to RLD and its variants using unmatched backward projection.\n\n**This [napari] plugin was generated with [copier] using the [napari-plugin-template].*\n\n## **Installation**\n\nYou must install `napari` firstly and then install `napari-kld`.\n\n### **Install `napari`**\n\nYou can download the `napari` bundled app for a simple installation via https://napari.org/stable/tutorials/fundamentals/quick_start.html#installation.\n\nOr, you can install `napari` with Python using pip:\n\n```\nconda create -y -n napari-env -c conda-forge python=3.10\nconda activate napari-env\npython -m pip install 'napari[all]'\n```\n\nRefer to https://napari.org/stable/tutorials/fundamentals/quick_start.html#installation.\n\n### **Install `napari-kld`**\n\nYou can install `napari-kld` plugin with `napari`:\n\n`Plugins` > `Install/Uninstall Plugins\u2026` > [search napari-kld] > `install`.\n\n\nOr you can install `napari-kld` via [pip]:\n\n    pip install napari-kld\n\n## **Instruction**\nThis plugin includes two part:\n\n- `RL Deconvolution` : Conventional RLD algorithm using different type of backward kernels (including matched backward kernel [`Traditional`] and unmatched backward kernels [`Guassian`, `Butterworth`, `Wiener-Butterworth (WB)`]). The forward kernel, i.e., point spread function (PSF), is required.\n\n- `KL Deconvolution` : KLD using learned forward/backward kernels.\n\n**You can download the `\"test\"` folder  at https://github.com/qiqi-lu/kernel-learning-deconvolution for testing, which save some 2D/3D images used for training and testing.**\n\n## **RL Deconvolution**\n\nThe conventional RLD using different type of backward kernels.\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `RL Deconvolution`\n\n2. Load input low-resolution (LR) image: `File` > `Open File(s)` > `[choose the image to be deconvolved]` > `[the image will appear in the layer list of napari]`, such as the simulated image `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/raw/0.tif\"`.\n\n3. Choose the name of loaded image in `Input RAW data`, such as `\"0\"`.\n\n4. Press `Choose` to choose a `PSF` correspongding to the loaded image, such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/psf.tif\"`.\n\n5. Choose the type of backward kernel in `Method` combo box:\n\n    - `Traditional` : the backward kernel is just the flip of forward kernel (i.e., PSF).\n    - `Guassian` : Guassian-shaped backward kernel, thw FWHM of which is same as the forward kernel.\n    - `Butterworth` : Butterworth-shaped backward kernel, which is constructed using Butterworth filter.\n    - `WB` : WB-shaped backward kernel, which is constructed by combining Wiener and Butterworth filter.\n\n6. Set the number of RL iterations `Iterations` and parameters of backward kernel*.\n\n7. Press `run` button to do deconvolution.\n\n8. Wait the `progress bar` to reach 100%.\n\n9. The output deconved image will appear in the layer list named as `{name of input image}_deconv_{Method}_iter_{Iterations}`, such as `\"0_deconv_traditional_iter_30\"`.\n\n**The adjustment of parameters of backward kernels should refer to the paper : Guo, M. et al. Rapid image deconvolution and multiview fusion for optical microscopy. Nat Biotechnol 38, 1337\u20131346 (2020).*\n\n## **KL Deconvolution**\n\n### **Training data preparation**\n\nThe data used for training must be prepared in a folder consisting of:\n\n- A folder named `\"gt\"` (optional) , such as `\"test/data/real/2D/train/gt\"`, which saves all the GT images (only support .tif file).\n- A folder named `\"raw\"`, such as `\"test/data/real/2D/train/raw\"`, which saves all the LR images (only support .tif file). The file names must be the same as those in `\"gt\"` folder.\n- A file named `\"train.txt\"`, such as `\"test/data/real/2D/train/train.txt\"`, which saves the name of each image in `\"gt\"/\"raw\"` filder in each line.\n\n### **When yuo have paired LR image and HR image**\n\nWhen we have paired LR image and HR image, we can treat LR image as **raw input** and HR image as **ground truth** (GT). We can first learn the forward kernel and then learn the backward kernel in a **supervised strategy**.\n\n#### **Training of Forward Projection**\n\nTrain the forward projection to learn forward kernel.\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory`, such as `\"test/data/real/2D/train\"`. Then the dimention of training data will show in the `Dimension` box.\n\n4. Choose `Output Directory`, such as `\"test/data/real/2D\"`.\n\n5. `PSF Directory` is not required as the PSF is unknown.\n\n6. If the raw input and GT image have different intensity, please check the `Preprocess` check box, which will rescale the input and GT images to have the same intensity. Here, do not check.\n\n7. In the `Forward Projection` box, set the parameters of training:\n    - `Epoch` : number of epochs of training.\n    - `Batch Size` : batch size of training data used during training.\n    - `Kernel Size (z, xy)` : the size of forward kernel to learned.\n    - `Optimizer` : the optimization algorithm. Default: Adam.\n    - `Learning Rate` : learning rate of training.\n    - `Decay Step` \uff1a the decay step of learning rate. Note: `0` for no decay.\n    - `Decay Rate` : the decay rate of learning rate.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100% and training finished.\n\nAfter the training of forward projection, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `forward_bs_{batch size}_lr_{learning rate}_ks_{kernel size (z)}_{kernel size (xy)}`, such as `\"test/data/real/2D/checkpoints/forward_bs_1_lr_0.001_ks_1_31\"`, which consists of:\n- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.\n- many model checkpoints, named as `epoch_{epoch}.pt`.\n- a `parameters.json` file saving the parameters used to training the model.\n\n#### **Training of Backward Projection**\n\nAfter training of forward projeciton, we can freeze the forward projeciton and then train the backward projeciton.\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory`, such as `\"test/data/2D/real/train\"`. Then the dimention of training data will show in the `Dimension` box.\n\n4. Choose `Output Directory`, such as `\"test/data/2D/real\"`.\n\n5. `PSF Directory` is no required as the PSF is unknown.\n\n6. If the raw input and GT image have different intensity, please check the `Preprocess` check box, which will rescale the input and GT images to have the same intensity. Here, do not check.\n\n7. In the `Backward Projeciton` box, set parameters for the trianing of backward projeciton.\n\n    - `Training strategy` : `supervised` training or `self-supervised` training. Here, set as `supervised`, as we have the GT images. When choosing the `self-supervised` mode, a PSF is required.\n    - `Iterations (RL)` : The number of iterations of RL iterative procedure. Default: 2.\n    - `Epoch` : The number fo epochs used to traing the model.\n    - `Batch Size` : The batch size used to training the model.\n    - `Kernel Size (z, xy)`: The size of backward kernel, `x` and `y` have the same size.\n    - `FP directory` : the directory of the pre-trained forward projeciton model, such as `\"test/data/real/2D/checkpoints/forward_bs_1_lr_0.001_ks_1_31/epoch_500_final.pt\"` (commonly the model labeled with `\"_final\"` is used).\n    - `Optimizer` : Optimization algorithm. Default: Adam.\n    - `Learning Rate` : The learning rate used to trianing the model.\n    - `Decay Step` : the decay step of learning rate.\n    - `Decay Rate` : the decay rate of learning rate.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100% and then the training finishes.\n\nWhen the training finishes, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}`, such as `\"test/data/real/2D/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_1_31\"`, which consists of:\n\n- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.\n- many model checkpoints, named as `epoch_{epoch}.pt`.\n- a `parameters.json` file saving the parameters used to training the model.\n\nNow we get the learned forward projection and backward projection.\n\nNext, we can use them to do `Prediction`.\n\n### **When you only have a PSF**\n\nWhen you only have a PSF to do deconvolution, you can train the model using simulated data following the below steps:\n\n1. Generate simulaiton data.\n2. Train the model under supervised mode.\n3. Apply the trained model on real data.\n\n#### **Simulation data generation**\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Simulation` tab.\n\n3. Choose the `Output Directory` of the generated simulation data, such as `\"test\\data\\simulation\"`.\n\n4. Choose the `PSF Directory` (only support 2D/3D PSF file save as .tif, axes = (y, x) or (z, y, x)), such as `\"test\\data\\simulation\\psf.tif\"`.\n\n5. Adjust the parameters as needed.\n    - `Image Shape` : the shape of simulated image, when `z=1`, 2D image will be generated.\n    - `PSF Crop` : when the input PSF is too large, you can crop the PSF to acuqire a smaller PSF. All the PSF will be converted to have an odd shape and normalized.\n    - `Num of Simulations` : number of generated images.\n    - `Gaussian (std)` : the standard deviation (std) of Gaussian noise added in the generated LR images. The mean of Gaussian noise = 0. Default: 0 (i.e., without gaussian noise).\n    - `Poisson` : whether to add Poisson noise, if `True`, make the `Enable` checked.\n    - `Ratio` : a ratio factor multiplied on GT image to control the level of Poisson noise, thus the simulated raw input LR image RAW can be expressed as:\n\n    $$ RAW = Possion((GT \\cdot Ratio)\\times PSF) + Gaussian $$\n\n    - `Scale Factor` : downsampling scale factor. Default: 1.\n\n6. Press `run` button.\n\n7. Wait the `progress bar` to reach 100%.\n\nThe generated simulation data will be save in `Output directory`, named as `\"data_{shape_z}_{shape_y}_{shape_x}_gauss_{std of Gaussian noise}_poiss_{whether to add Poisson noise}_ratio_{Ratio}\"`, such as: `\"test\\data\\simulation\\data_128_128_128_gauss_0.0_poiss_0_ratio_1.0\\train\"`\n\n- `\"data\\train\\gt\"` saves the GT images which consist of structures with various shapes*.\n- `\"data\\train\\raw\"` saves the RAW images with blur and noise.\n- `\"data\\train\\parameters.json\"` is a dictionary of parameters used to generate the simulation data.\n- `\"data\\train\\psf.tif\"` is the PSF used in the simulation data generation (as the original PSF may be cropped).\n- `\"data\\train\\train.txt` save all the image used to train the model.\n\nAfter you generate simulation data, you can use them to train the model.\n\n**the code was refered to the paper: Li, Y. et al. Incorporating the image formation process into deep learning improves network performance. Nat Methods 19, 1427\u20131437 (2022).*\n\n*You may need to adjust the noise level in the image accordding to the real acuqired data.*\n\n#### **Training with known PSF and simulated data**\n\nThe simulated data should be those generated using the known PSF.\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory`, such as `test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train\"`, which saves the data used to train the model in should include:\n    - A `gt` folder saves the GT images\n    - A `raw` folder save the raw input LR images with the same file name as GT images\n    - A `train.txt` file saves all the file names used to train the model (does not need to list all the files in `gt`/`raw` folder but at least one).\n\n4. Choose a `Output Directory` to save the model checkpoints, such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0\"`.\n\n5. Choose `PSF Directory` of the PSF corresponding to the data, such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/psf.tif\"`. Then the `Forward Projection` group box will be invisible as we do not need to learn the forward kernel when we know the PSF. Just use the PSF as the forward kernel.\n\n6. If the raw input and GT image have different intensity, please check the `Preprocess` check box, which will rescale the input and GT images to have the same intensity. Here, do not check.\n\n7. Then set parameters to learn the backward kernel.\n\n    - `Training Strategy` : `supervised` training or `self-supervised` training. Here, set as `supervised`, as we have the GT images.\n    - `Iterations (RL)` : the number of iterations of RL iteration procedure. Default: 2.\n    - `Epoch` : the number fo epochs used to traing the model.\n    - `Batch Size` : the batch size used to training the model.\n    - `Kernel Size (z, xy)`: the size of backward kernel, `x` and `y` directions have the same size.\n    - `FP Directory` : the directory of the forward projeciton model. Here, it is disabled as the PSF is known.\n    - `Optimizer` : Optimization algorithm. Default: Adam.\n    - `Learning Rate` : the learning rate used to trianing the model.\n    - `Decay Step` : the decay step of learning rate.\n    - `Decay Rate` : the decay rate of learning rate.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100% and the training finishes.\n\nWhen the training finishes, a checkpoints folder will be created in `Output Directory` such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/checkpoints\"`.\n\nThe models is save in `/checkpoints` folder, which is named as `\"backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}\"`, such as `\"/checkpoints/backward_bs_1_lr_1e-06_iter_2_ks_1_31\"`, consists of:\n\n- A `log` folder saved the `Tensorboard` log, which can be open with `Tensorboard`.\n- Many model checkpoints, named as `epoch_{epoch}.pt`.\n- A `parameters.json` file saving the parameters used to training the model.\n\n### **When you only have LR image and corresponding PSF**\nWhen we only have LR image and its PSF, we can traing the backward projection through supervised training using simulation data as introduced above. The plugin also provide an alternative self-supervised training stratergy to learn the backward kernel.\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory`, such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train\"`.\n\n4. choose `Output Directory`, such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0\"`.\n\n5. Choose `PSF Directory`, such as `\"test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/psf.tif\"` then the `Forward Projection` box will be invisiable.\n\n6. As there is no GT image, preprocessing is not needed. Do not check `Preprocess` check box.\n\n7. In the `Backward Projeciton` box, set parameters for the trianing of backward projeciton.\n\n    - `Training strategy` : `supervised` training or `self-supervised` training. Set as `self-supervised`, as we do not have the GT images.\n    - `Iterations (RL)` : the number of iterations of RL iteration procedure. Default: 2.\n    - `Epoch` : the number fo epochs used to traing the model.\n    - `Batch Size` : the batch size used to training the model.\n    - `Kernel Size (z, xy)`: the size of backward kernel, `x` and `y` directions have the same size.\n    - `FP Directory` : the directory of the forward projeciton model. Here, it is disabled as the PSF is known.\n    - `Optimizer` : Optimization algorithm. Default: Adam.\n    - `Learning Rate` : the learning rate used to trianing the model.\n    - `Decay Step` : the decay step of learning rate.\n    - `Decay Rate` : the decay rate of learning rate.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100% and training finishes.\n\nWhen the training finishes, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}_ss`, such as `\"/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_31_31_ss\"`, which consists of:\n\n- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.\n- many model checkpoints, named as `epoch_{epoch}.pt`.\n- a `parameters.json` file saving the parameters used to training the model.\n\n*The performance of self-supervised learning may be inferior to supervised learning according to our experiments.*\n\n### **Prediction**\nUse the learned forward/backward kernel to do deconvolution.\n\n1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Prediction` tab.\n\n3. Load raw input low-resolution image through `napari`: `File` > `Open File(s)` > `[choose the image to be deconvolved]` > `[the image will appear in the layer list of napari]`, such as `\"test/data/real/2D/test/raw/2.tif\"`.\n\n4. Choose the loaded image in `Input RAW data` box, e.g., `2`.\n\n5. If the PSF is known, choose the `PSF directory`.\n\n6. If the PSF is unknown, choose the `Forward Projection` directory, such as `\"test/data/real/2D/checkpoints/forward_bs_1_lr_0.001_ks_1_31/epoch_500_final.pt\"` (commonly the model labeled with `\"_final\"` is used). If both the directories of PSF and Forward Projeciton is choosen, KLD will directly use the PSF selected.\n\n7. Choose the `Backward Projeciton` directory, such as `\"test/data/real/2D/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_1_31/epoch_1000_final.pt\"`  (commonly the model labeled with `\"_final\"` is used).\n\n8. Set the number of RL iterations at `Iterations (RL)`. Default: 2.\n\n9. Press run to do deconvolution.\n\n10. Wait the progress bar to reach 100%.\n\nThe deconvolved image will be directly shown in the `layer list` of `napari`, named as `\"{input data name}_deconvo_iter_{number of RL iterations}\"`, e.g., `\"16_deconv_iter_2\"`. You can save it as needed.\n\n### **Others**\nThe `log` tab print the message during running.\nPress `clean` button will clean all the text in the `log` box.\n\n### **Notice**\n\n- *Currently, the plugin is runned on CPU. We have tried to run the training on GPU, but the training time did not decrease (maybe it is because the FFT-based covnlution was not optimized on GPU). We are trying to make improvements.*\n\n- *The training time may be very long if we set the kernel size or the number of epoches too large, especially for 3D images. Besides, it also depends on the  computation capability of your device.*\n\n## Contributing\n\nContributions are very welcome. Tests can be run with [tox], please ensure\nthe coverage at least stays the same before you submit a pull request.\n\n## License\n\nMIT LICENSE\n\n## Issues\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n[napari]: https://github.com/napari/napari\n[copier]: https://copier.readthedocs.io/en/stable/\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause\n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt\n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt\n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt\n[napari-plugin-template]: https://github.com/napari/napari-plugin-template\n\n[napari]: https://github.com/napari/napari\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Qiqi Lu",
    "author_email": "136303971@qq.com",
    "maintainer": null,
    "maintainer_email": null,
    "license": "\nCopyright (c) 2024, Qiqi Lu\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "classifier": [
      "Development Status :: 2 - Pre-Alpha",
      "Framework :: napari",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.12",
      "Topic :: Scientific/Engineering :: Image Processing"
    ],
    "requires_dist": [
      "numpy==1.26.4",
      "magicgui",
      "qtpy",
      "scikit-image",
      "torch==2.0",
      "torchvision",
      "fft-conv-pytorch",
      "pytorch-msssim",
      "tensorboard",
      "pydicom",
      "tox; extra == \"testing\"",
      "pytest; extra == \"testing\"",
      "pytest-cov; extra == \"testing\"",
      "pytest-qt; extra == \"testing\"",
      "napari; extra == \"testing\"",
      "pyqt5; extra == \"testing\""
    ],
    "requires_python": ">=3.9",
    "requires_external": null,
    "project_url": null,
    "provides_extra": [
      "testing"
    ],
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}