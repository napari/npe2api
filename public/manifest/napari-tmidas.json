{
  "name": "napari-tmidas",
  "display_name": "T-MIDAS",
  "visibility": "public",
  "icon": "",
  "categories": [
    "Annotation",
    "Segmentation",
    "Acquisition"
  ],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "napari-tmidas.get_reader",
        "title": "Open data with T-MIDAS",
        "python_name": "napari_tmidas._reader:napari_get_reader",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas.write_multiple",
        "title": "Save multi-layer data with T-MIDAS",
        "python_name": "napari_tmidas._writer:write_multiple",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas.write_single_image",
        "title": "Save image data with T-MIDAS",
        "python_name": "napari_tmidas._writer:write_single_image",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas.make_sample_data",
        "title": "Load sample data from T-MIDAS",
        "python_name": "napari_tmidas._sample_data:make_sample_data",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas._label_inspection",
        "title": "Label Inspector",
        "python_name": "napari_tmidas._label_inspection:label_inspector_widget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas.file_selector",
        "title": "Batch Image Processing",
        "python_name": "napari_tmidas._file_selector:napari_experimental_provide_dock_widget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas._file_conversion",
        "title": "Microscopy Image Converter",
        "python_name": "napari_tmidas._file_conversion:napari_experimental_provide_dock_widget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas._crop_anything",
        "title": "Batch Crop Anything",
        "python_name": "napari_tmidas._crop_anything:batch_crop_anything_widget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-tmidas._roi_colocalization",
        "title": "Batch ROI Colocalization Analysis",
        "python_name": "napari_tmidas._roi_colocalization:roi_colocalization_analyzer",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": [
      {
        "command": "napari-tmidas.get_reader",
        "filename_patterns": [
          "*.npy"
        ],
        "accepts_directories": false
      }
    ],
    "writers": [
      {
        "command": "napari-tmidas.write_multiple",
        "layer_types": [
          "image*",
          "labels*"
        ],
        "filename_extensions": [],
        "display_name": ""
      },
      {
        "command": "napari-tmidas.write_single_image",
        "layer_types": [
          "image"
        ],
        "filename_extensions": [
          ".npy"
        ],
        "display_name": ""
      }
    ],
    "widgets": [
      {
        "command": "napari-tmidas.file_selector",
        "display_name": "Batch Image Processing",
        "autogenerate": false
      },
      {
        "command": "napari-tmidas._label_inspection",
        "display_name": "Batch Label inspection",
        "autogenerate": false
      },
      {
        "command": "napari-tmidas._file_conversion",
        "display_name": "Batch Microscopy Image Conversion",
        "autogenerate": false
      },
      {
        "command": "napari-tmidas._crop_anything",
        "display_name": "Batch Crop Anything",
        "autogenerate": false
      },
      {
        "command": "napari-tmidas._roi_colocalization",
        "display_name": "Batch ROI Colocalization Analysis",
        "autogenerate": false
      }
    ],
    "sample_data": [
      {
        "command": "napari-tmidas.make_sample_data",
        "key": "unique_id.1",
        "display_name": "T-MIDAS"
      }
    ],
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.4",
    "name": "napari-tmidas",
    "version": "0.2.6",
    "dynamic": [
      "license-file"
    ],
    "platform": null,
    "supported_platform": null,
    "summary": "A plugin for batch processing of confocal and whole-slide microscopy images of biological tissues",
    "description": "# napari-tmidas\n\n[![License BSD-3](https://img.shields.io/pypi/l/napari-tmidas.svg?color=green)](https://github.com/macromeer/napari-tmidas/raw/main/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/napari-tmidas.svg?color=green)](https://pypi.org/project/napari-tmidas)\n[![Python Version](https://img.shields.io/pypi/pyversions/napari-tmidas.svg?color=green)](https://python.org)\n[![Downloads](https://static.pepy.tech/badge/napari-tmidas)](https://pepy.tech/project/napari-tmidas)\n[![DOI](https://zenodo.org/badge/698257324.svg)](https://zenodo.org/badge/latestdoi/698257324)\n[![tests](https://github.com/macromeer/napari-tmidas/workflows/tests/badge.svg)](https://github.com/macromeer/napari-tmidas/actions)\n\nThis napari plugin consists of a growing collection of pipelines for fast batch processing of confocal and whole slide microscopy images of biological tissues. This is a WIP and based on the [T-MIDAS terminal](https://github.com/MercaderLabAnatomy/T-MIDAS).\n\n## Features\nCurrently, **napari-tmidas** provides pipelines as widgets for batch image conversion and processing, object cropping, label image inspection and ROI colocalization (cf. [usage](#usage) below). You can request new batch image processing features in [issues](https://github.com/MercaderLabAnatomy/napari-tmidas/issues).\n\n## Installation\n\n(Video installation guides: https://www.youtube.com/@macromeer/videos)\n\nFirst, install Napari in a virtual environment:\n\n    mamba create -y -n napari-tmidas -c conda-forge python=3.11\n    mamba activate napari-tmidas\n    python -m pip install \"napari[all]\"\n\nNow you can install `napari-tmidas` via [pip]:\n\n    pip install napari-tmidas\n\n**For deep learning features** (Batch Crop Anything with SAM2, Spotiflow, Careamics, Trackastra), also install:\n\n    pip install 'napari-tmidas[deep-learning]'\n\nOr install everything at once:\n\n    pip install 'napari-tmidas[all]'\n\nIt is recommended though to install the **latest development version**. Please also execute this command from time to time in the activated environment to benefit from newly added features:\n\n    pip install git+https://github.com/MercaderLabAnatomy/napari-tmidas.git\n\n### Additional Setup for Batch Crop Anything\n\nTo use the Batch Crop Anything pipeline with SAM2, you only need to install ffmpeg manually. SAM2 and its model checkpoints will be automatically installed when you first run the pipeline:\n\n    mamba install -c conda-forge ffmpeg\n\nIf you want to batch compress image data using [Zstandard](https://github.com/facebook/zstd), use the package manager of your operating system to install it:\n\n   ~~sudo apt-get install zstd~~    # Pre-installed on Linux :man_shrugging:\n\n    brew install zstd            # for macOS (requires Homebrew)\n    pip install zstandard        # Windows with Python >= 3.7\n\nAnd you are done!\n\n## Usage\n\nTo use the plugin, start napari in the activated virtual environment with this terminal command:\n\n    mamba run -n napari-tmidas napari\n\nYou can then find the installed plugin in the Plugins tab.\n\n### Microscopy Image Conversion\n\nConverts `.lif, .nd2, .czi, .ndpi` and Acquifer data to TIF or OME-Zarr formats. Scan a folder, select files, and export with preserved spatial metadata.\n\n**Supported Formats:**\n- **TIF** - Standard format for compatibility\n- **OME-Zarr** - Recommended for large datasets, [spec v0.5](https://ngff.openmicroscopy.org/latest/) compliant with automatic physical metadata extraction (voxel sizes, spacing)\n\n<img src=\"https://github.com/user-attachments/assets/e377ca71-2f30-447d-825e-d2feebf7061b\" alt=\"Microscopy Image Conversion Widget\" style=\"width:75%; height:auto;\">\n\n\n### Image Processing\n\n1. You start with entering the path to the folder containing the images to be processed (currently supports TIF, later also ZARR) and optionally a filter for filename suffix\n\n![image](https://github.com/user-attachments/assets/41ecb689-9abe-4371-83b5-9c5eb37069f9)\n\n2. After indexing the files, a table appears with the found images. You can click on them to inspect them in the viewer.\n\n![image](https://github.com/user-attachments/assets/8360942a-be8f-49ec-bc25-385ee43bd601)\n\n3. Next, select a processing function, set parameters if applicable and `Start Batch Processing`.\n\n![image](https://github.com/user-attachments/assets/05929660-6672-4f76-89da-4f17749ccfad)\n\n4. You can click on the images in the table to show them in the viewer. For example first click on one of the `Original Files`, and then the corresponding `Processed File` to see an overlay.\n\n<img src=\"https://github.com/user-attachments/assets/cfe84828-c1cc-4196-9a53-5dfb82d5bfce\" alt=\"Image Processing Widget\" style=\"width:75%; height:auto;\">\n\n\nNote that whenever you click on an `Original File` or `Processed File` in the table, it will replace the one that is currently shown in the viewer. So naturally, you'd first select the original image, and then the processed image to correctly see the image pair that you want to inspect.\n\n\n#### Processing Function Credits\n\nThe image processing capabilities are powered by several excellent open-source tools:\n- [Cellpose 4](https://github.com/MouseLand/cellpose): Advanced cell segmentation\n- [Trackastra](https://github.com/weigertlab/trackastra): Cell tracking and analysis\n- [VisCy](https://github.com/mehta-lab/VisCy): Virtual staining using deep learning\n- [CAREamics](https://github.com/CAREamics/careamics): Content-aware image restoration and enhancement\n- [Spotiflow](https://github.com/weigertlab/spotiflow): Accurate and efficient spot detection for fluorescence microscopy\n\n#### Processing Function Documentation\n\nDetailed documentation for specific processing functions:\n\n**Core Processing**\n- [Basic Processing Functions](docs/basic_processing.md) - Label and intensity operations, channel splitting/merging, time series\n- [Cellpose Segmentation](docs/cellpose_segmentation.md) - Deep learning cell/nucleus segmentation\n- [TrackAstra Tracking](docs/trackastra_tracking.md) - Cell tracking across time-lapse data\n- [VisCy Virtual Staining](docs/viscy_virtual_staining.md) - Virtual staining of phase/DIC images using deep learning\n\n**Analysis and Quality Control**\n- [Grid View: Intensity + Labels Overlay](docs/grid_view_overlay.md) - Visual QC for segmentation results\n- [Intensity-Based Label Filtering](docs/intensity_label_filter.md) - Filter labels by signal intensity\n- [Regionprops Analysis](docs/regionprops_analysis.md) - Extract quantitative properties from labels\n\n**Advanced Processing**\n- [Advanced Processing Functions](docs/advanced_processing.md) - Denoising (CAREamics), spot detection (Spotiflow), SciPy/scikit-image filters, compression, colocalization\n\n### Batch Label Inspection\nIf you have already segmented a folder full of images and now you want to maybe inspect and edit each label image, you can use the `Plugins > T-MIDAS > Batch Label Inspection`, which automatically saves your changes to the existing label image once you click the `Save Changes and Continue` button (bottom right).\n\n<img src=\"https://github.com/user-attachments/assets/0bf8c6ae-4212-449d-8183-e91b23ba740e\" alt=\"Batch Label Inspection Widget\" style=\"width:75%; height:auto;\">\n\n### Crop Anything\n\nThis pipeline combines the Segment Anything Model (SAM2; supports YX, ZYX and TYX data) for automatic object detection with an interactive interface for selecting and cropping multiple objects from images. To launch the widget, open `Plugins > T-MIDAS > Batch Crop Anything`. Cropping works like this: Enter 2D view and go to the first z slice where the object to be cropped is appearing. Activate/select the points layer and click on the object. Terminal shows progress. You can then proceed to select another object (always do this in 2D mode)\n\n<img src=\"https://github.com/user-attachments/assets/6d72c2a2-1064-4a27-b398-a9b86fcbc443\" alt=\"Crop Anything Widget\" style=\"width:75%; height:auto;\">\n\n\n\n\n### ROI Colocalization\n\nThis pipeline quantifies colocalization between labeled regions of interest (ROIs) across multiple image channels. It determines the extent of overlap between ROIs in a reference channel and those in one or two other channels. The output is a table of colocalization counts. Optionally, the size of reference channel ROIs, as well as the total or median size of colocalizing ROIs in the other channels, can be included. Colocalization is determined using Boolean masking. The number of colocalizing instances is determined by counting unique label IDs within the overlapping regions. Typically, the reference channel contains larger structures, while other channels contain smaller, potentially nested, structures. For example, the reference channel might contain cell bodies, with the second and third channels containing nuclei and sub-nuclear objects, respectively.\n\n<img src=\"https://github.com/user-attachments/assets/2f9022a0-7b88-4588-a448-250f07a634d7\" alt=\"ROI Colocalization Widget\" style=\"width:75%; height:auto;\">\n\n## Contributing\n\nContributions are very welcome. Tests can be run with [tox], please ensure\nthe coverage at least stays the same before you submit a pull request.\n\n## License\n\nDistributed under the terms of the [BSD-3] license,\n\"napari-tmidas\" is free and open source software\n\n## Issues\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n[napari]: https://github.com/napari/napari\n[copier]: https://copier.readthedocs.io/en/stable/\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause\n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt\n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt\n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt\n[napari-plugin-template]: https://github.com/napari/napari-plugin-template\n\n[file an issue]: https://github.com/macromeer/napari-tmidas/issues\n\n----------------------------------\n\nThis [napari] plugin was generated with [copier] using the [napari-plugin-template].\n\n<!--\nDon't miss the full getting started guide to set up your new package:\nhttps://github.com/napari/napari-plugin-template#getting-started\n\nand review the napari docs for plugin developers:\nhttps://napari.org/stable/plugins/index.html\n-->\n\n[napari]: https://github.com/napari/napari\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Marco Meer",
    "author_email": "marco.meer@pm.me",
    "maintainer": null,
    "maintainer_email": null,
    "license": "Copyright (c) 2025, Marco Meer\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "classifier": [
      "Development Status :: 2 - Pre-Alpha",
      "Framework :: napari",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: MacOS",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Topic :: Scientific/Engineering :: Image Processing"
    ],
    "requires_dist": [
      "numpy<2.0,>=1.23.0",
      "magicgui",
      "tqdm",
      "qtpy",
      "scikit-image>=0.19.0",
      "scikit-learn-extra>=0.3.0",
      "pyqt5",
      "zarr",
      "ome-zarr",
      "napari-ome-zarr",
      "nd2",
      "pylibCZIrw",
      "readlif",
      "tiffslide",
      "acquifer-napari",
      "tox; extra == \"testing\"",
      "pytest>=7.0.0; extra == \"testing\"",
      "pytest-cov; extra == \"testing\"",
      "pytest-qt; extra == \"testing\"",
      "pytest-timeout; extra == \"testing\"",
      "napari; extra == \"testing\"",
      "pyqt5; extra == \"testing\"",
      "psygnal>=0.8.0; extra == \"testing\"",
      "scikit-learn-extra>=0.3.0; extra == \"clustering\"",
      "torch>=1.12.0; extra == \"deep-learning\"",
      "torchvision>=0.13.0; extra == \"deep-learning\"",
      "timm; extra == \"deep-learning\"",
      "opencv-python; extra == \"deep-learning\"",
      "cmake; extra == \"deep-learning\"",
      "hydra-core; extra == \"deep-learning\"",
      "eva-decord; extra == \"deep-learning\"",
      "napari-tmidas[clustering,deep-learning,testing]; extra == \"all\""
    ],
    "requires_python": ">=3.10",
    "requires_external": null,
    "project_url": [
      "Bug Tracker, https://github.com/macromeer/napari-tmidas/issues",
      "Documentation, https://github.com/macromeer/napari-tmidas#README.md",
      "Source Code, https://github.com/macromeer/napari-tmidas",
      "User Support, https://github.com/macromeer/napari-tmidas/issues"
    ],
    "provides_extra": [
      "testing",
      "clustering",
      "deep-learning",
      "all"
    ],
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}