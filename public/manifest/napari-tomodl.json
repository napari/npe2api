{
  "name": "napari-tomodl",
  "display_name": "ToMoDL Reconstruction",
  "visibility": "public",
  "icon": "",
  "categories": [],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "napari-tomodl.make_reconstruct_widget",
        "title": "Reconstruct OPT data with ToMoDL",
        "python_name": "napari_tomodl._reconstruction_widget:ReconstructionWidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": null,
    "writers": null,
    "widgets": [
      {
        "command": "napari-tomodl.make_reconstruct_widget",
        "display_name": "napari-ToMoDL",
        "autogenerate": false
      }
    ],
    "sample_data": null,
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "napari-tomodl",
    "version": "0.2.19",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "A plugin for optical projection tomography reconstruction with model-based neural networks.",
    "description": "# napari-tomodl\n\n[![License MIT](https://img.shields.io/pypi/l/napari-tomodl.svg?color=green)](https://github.com/marcoso96/napari-tomodl/raw/main/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/napari-tomodl.svg?color=green)](https://pypi.org/project/napari-tomodl)\n[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomodl.svg?color=green)](https://python.org)\n<!-- [![tests](https://github.com/marcoso96/napari-tomodl/workflows/tests/badge.svg)](https://github.com/marcoso96/napari-tomodl/actions) -->\n[![codecov](https://codecov.io/gh/marcoso96/napari-tomodl/branch/main/graph/badge.svg)](https://codecov.io/gh/marcoso96/napari-tomodl)\n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tomodl)](https://napari-hub.org/plugins/napari-tomodl)\n\nA plugin for optical projection tomography reconstruction with model-based neural networks.\n\n----------------------------------\n\nThis [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.\n\n<!--\nDon't miss the full getting started guide to set up your new package:\nhttps://github.com/napari/cookiecutter-napari-plugin#getting-started\n\nand review the napari docs for plugin developers:\nhttps://napari.org/stable/plugins/index.html\n-->\n## \ud83d\udd2c Introduction\n\n**napari-tomodl** is a [napari](https://napari.org/) plugin that enables users to easily reconstruct tomography images directly from raw projection data. Simply load an ordered stack of projection files into the napari viewer, and the plugin takes care of reconstructing the corresponding tomographic volume.  \n\n## \ud83d\ude80 Usage\n\n1. **Load ordered stack**  \n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/stack_image.png)\n\n   Go to **File \u2192 Open Files as Stack...** and load the angular projections for parallel beam optical tomography reconstruction.\n\n2. **Select image layer**  \n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/select_layer.png) \n\n   In the dropdown menu, click **Select image layer** and choose the loaded volume.  \n\n<!--  make this line be bigger and bold -->\n<h3>From here you can choose between two reconstruction modes: Basic and Advanced.</h3>\n\n### \ud83d\udd39 Basic Mode\n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/basic_mode.png)  \n\n3. **Half-rotation**  \n   - Click **Half rotation** if your projection data was acquired from 0\u00b0 to 180\u00b0.  \n   - Leave it unchecked if data was acquired from 0\u00b0 to 360\u00b0.\n\n4. **Automatic axis alignment**  \n   If the rotation axis is not correctly aligned during acquisition, enable **Automatic axis alignment**.  This aligns the sinogram to the detector center using the [Wall-method].\n\n5. **Compression**  \n   Projection images are assumed to have shape **(Theta, Detector size, Z)** in vertical axis mode.  \n   You can compress along the Z-axis:  \n   - **HIGH** \u2192 resize Z to 100  \n   - **MEDIUM** \u2192 resize Z to 256  \n   - **LOW** \u2192 resize Z to 512  \n   - **NO** \u2192 no compression  \n\n6. **Reconstruction method**  \n   - **FBP CPU / FBP GPU** \u2192 from the [QBI_radon] library  \n   - **TOMODL CPU / TOMODL GPU / UNET CPU / UNET GPU** \u2192 proposed in our [ToMoDL-paper]  \n\n7. **Smoothing level**  \n   Select smoothing strength (only applies to **TOMODL** methods). Can be adjusted in the **Advanced mode**.\n    - **LOW** \u2192 2  \n    - **MEDIUM** \u2192 4  \n    - **HIGH** \u2192 6 \n\n8. **Rotation axis**  \n   - **Vertical** \u2192 for data shape (Theta, Detector size, Z)  \n   - **Horizontal** \u2192 for data shape (Theta, Z, Detector size)\n---\n\n### \ud83d\udd39 Advanced Mode\n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/advanced_model.png)  \n\n9. **Manual axis alignment**  \n   Shift the object along the detector axis (Z-axis).  \n   - Negative values \u2192 shift left  \n   - Positive values \u2192 shift right  \n\n10. **Reshape volume**  \n    Select a reconstruction size (alternative to compression levels from Basic mode).\n\n11. **Flat-field correction**  \n    Apply flat-field correction to projection data before reconstruction.\n\n12. **Clip to circle**  \n    Constrain the reconstructed object inside a circular region.\n\n13. **Filter (FBP only)**  \n    Choose the filter to apply when using FBP methods. \n\n14. **Reconstruct full volume**  \n    - Enabled \u2192 reconstruct the whole volume.  \n    - Disabled \u2192 reconstruct only a subset of slices along the detector axis (faster for testing).\n\n15. **Batch size**  \n    Number of slices processed simultaneously:  \n    - Higher values \u2192 faster reconstruction but greater GPU memory usage.  \n    - On CPU \u2192 limited to processing **1 slice at a time**.  \n\n16. **Reconstruct only slices**  \n    - Enabled \u2192 reconstruct only a single slice at the specified index.  \n    - Disabled \u2192 reconstruct from index 0 up to the chosen slice index in the **# of slices to reconstruct** field.  \n\n17. **Invert colors**  \n    Invert grayscale values in the reconstructed volume.\n\n18. **16-bit conversion**  \n    Convert the reconstructed volume to **16-bit** for faster 3D rendering.  \n    Leave unchecked to keep **32-bit float** output.\n---\n\n19. **Reconstruct!** \n\n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/reconstruct_button.png)\n\n   A new layer will appear on top of the projections stack with the reconstructed volume.\n\n\n## \ud83d\udcbb Installation\nFollow these steps in <span style=\"color:red;\">**Napari\u2019s Python console**</span>.\n### **1. Install PyTorch**\n#### GPU (CUDA-compatible GPU)\n```python\nconda install pytorch==2.5.0 pytorch-cuda=12.1 -c pytorch -c nvidia\n```\n#### CPU-only (no GPU)\n```python\nconda install pytorch==2.5.0 cpuonly -c pytorch\n```\n\n### **2. Install the napari-tomodl plugin**\n```python\n!pip install napari-tomodl\n```\n\n> Tip: After installing PyTorch, restart Napari to ensure it detects the new environment. \ud83d\ude0a\n\n## \ud83e\udd1d Contributing\n\nContributions are very welcome. Tests can be run with [tox], please ensure\nthe coverage at least stays the same before you submit a pull request.\n\n## \ud83d\udcdc License\n\nDistributed under the terms of the [MIT] license,\n\"napari-tomodl\" is free and open source software\n\n## \ud83d\udc1bIssues\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n[napari]: https://github.com/napari/napari\n[Cookiecutter]: https://github.com/audreyr/cookiecutter\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause\n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt\n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt\n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt\n[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin\n\n[QBI_radon]: https://github.com/QBioImaging/QBI_radon\n[Wall-method]: https://doi.org/10.1088/0031-9155/50/19/015\n[ToMoDL-paper]: https://doi.org/10.1038/s41598-023-47650-3\n[napari]: https://github.com/napari/napari\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Marcos Antonio Obando, Minh Nhat Trinh, David Palecek, Germ\u00e1n Mato, Teresa Correia",
    "author_email": "marcos.obando@ib.edu.ar",
    "maintainer": null,
    "maintainer_email": null,
    "license": "MIT",
    "classifier": [
      "Development Status :: 2 - Pre-Alpha",
      "Framework :: napari",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Topic :: Scientific/Engineering :: Image Processing"
    ],
    "requires_dist": [
      "magicgui",
      "qtpy",
      "napari",
      "pyqt5",
      "opencv-python",
      "scikit-image",
      "scipy",
      "qbi-radon",
      "pyopengl ==3.1.6"
    ],
    "requires_python": ">=3.10",
    "requires_external": null,
    "project_url": null,
    "provides_extra": null,
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}