{
  "name": "napari-tomodl",
  "display_name": "ToMoDL Reconstruction",
  "visibility": "public",
  "icon": "",
  "categories": [],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "napari-tomodl.make_reconstruct_widget",
        "title": "Reconstruct OPT data with ToMoDL",
        "python_name": "napari_tomodl._reconstruction_widget:ReconstructionWidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": null,
    "writers": null,
    "widgets": [
      {
        "command": "napari-tomodl.make_reconstruct_widget",
        "display_name": "napari-ToMoDL",
        "autogenerate": false
      }
    ],
    "sample_data": null,
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "napari-tomodl",
    "version": "0.2.26",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "A plugin for optical projection tomography reconstruction with model-based neural networks.",
    "description": "# napari-tomodl\n\n[![License MIT](https://img.shields.io/pypi/l/napari-tomodl.svg?color=green)](https://github.com/marcoso96/napari-tomodl/raw/main/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/napari-tomodl.svg?color=green)](https://pypi.org/project/napari-tomodl)\n[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomodl.svg?color=green)](https://python.org)\n<!-- [![tests](https://github.com/marcoso96/napari-tomodl/workflows/tests/badge.svg)](https://github.com/marcoso96/napari-tomodl/actions) -->\n[![codecov](https://codecov.io/gh/marcoso96/napari-tomodl/branch/main/graph/badge.svg)](https://codecov.io/gh/marcoso96/napari-tomodl)\n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tomodl)](https://napari-hub.org/plugins/napari-tomodl)\n\nA plugin for optical projection tomography reconstruction with model-based neural networks.\n\n----------------------------------\n\nThis [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.\n\n<!--\nDon't miss the full getting started guide to set up your new package:\nhttps://github.com/napari/cookiecutter-napari-plugin#getting-started\n\nand review the napari docs for plugin developers:\nhttps://napari.org/stable/plugins/index.html\n-->\n## \ud83d\udd2c Introduction\n\n**napari-tomodl** is a [napari](https://napari.org/) plugin that enables users to easily reconstruct tomography images directly from raw projection data. Simply load an ordered stack of projection files into the napari viewer, and the plugin takes care of reconstructing the corresponding tomographic volume.  \n\n## \ud83d\ude80 Usage\n\n1. **Load ordered stack**  \n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/stack_image.png)\n\n   Go to **File \u2192 Open Files as Stack...** and load the angular projections for parallel beam optical tomography reconstruction.\n\n2. **Select image layer**  \n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/select_layer.png) \n\n   In the dropdown menu, click **Select image layer** and choose the loaded volume.  \n\n<!--  make this line be bigger and bold -->\n<h3>From here you can choose between two reconstruction modes: Basic and Advanced.</h3>\n\n### \ud83d\udd39 Basic Mode\n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/basic_mode.png)  \n\n3. **Half-rotation**  \n   - Click **Half rotation** if your projection data was acquired from 0\u00b0 to 180\u00b0.  \n   - Leave it unchecked if data was acquired from 0\u00b0 to 360\u00b0.\n\n4. **Automatic axis alignment**  \n   If the rotation axis is not correctly aligned during acquisition, enable **Automatic axis alignment**.  This aligns the sinogram to the detector center using the [Wall-method].\n\n5. **Compression**  \n   Projection images are assumed to have shape **(Theta, Detector size, Z)** in vertical axis mode.  \n   You can compress along the Z-axis:  \n   - **HIGH** \u2192 resize Z to 100  \n   - **MEDIUM** \u2192 resize Z to 256  \n   - **LOW** \u2192 resize Z to 512  \n   - **NO** \u2192 no compression  \n\n6. **Reconstruction method**  \n   - **FBP CPU / FBP GPU** \u2192 from the [QBI_radon] library  \n   - **TOMODL CPU / TOMODL GPU / UNET CPU / UNET GPU** \u2192 proposed in our [ToMoDL-paper]  \n\n7. **Smoothing level**  \n   Select smoothing strength (only applies to **TOMODL** methods). Can be adjusted in the **Advanced mode**.\n    - **LOW** \u2192 2  \n    - **MEDIUM** \u2192 4  \n    - **HIGH** \u2192 6 \n\n8. **Rotation axis**  \n   - **Vertical** \u2192 for data shape (Theta, Detector size, Z)  \n   - **Horizontal** \u2192 for data shape (Theta, Z, Detector size)\n---\n\n### \ud83d\udd39 Advanced Mode\n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/advanced_mode.png)\n\n9. **Manual axis alignment**  \n   Shift the object along the detector axis (Z-axis).  \n   - Negative values \u2192 shift left  \n   - Positive values \u2192 shift right  \n\n10. **Reshape volume**  \n    Select a reconstruction size (alternative to compression levels from Basic mode).\n\n11. **Flat-field correction**  \n    Apply flat-field correction to projection data before reconstruction.\n\n12. **Clip to circle**  \n    Constrain the reconstructed object inside a circular region.\n\n13. **Filter (FBP only)**  \n    Choose the filter to apply when using FBP methods. \n\n14. **Full volume mode**  \n    - Enabled \u2192 reconstruct the whole volume.  \n\n16. **One Slice mode**  \n    - Enabled \u2192 reconstruct only a single slice at the **# of slices to reconstruct** index. \n\n17. **Slices mode**\n    - Enabled \u2192 reconstruct from index 0 up to the chosen slice index in the **# of slices to reconstruct** field.  \n\n18. **Batch size**  \n    Number of slices processed simultaneously:  \n    - Higher values \u2192 faster reconstruction but greater GPU memory usage.  \n    - On CPU \u2192 limited to processing **1 slice at a time**.  \n\n19. **Invert colors**  \n    Invert grayscale values in the reconstructed volume.\n\n20. **16-bit conversion**  \n    Convert the reconstructed volume to **16-bit** for faster 3D rendering.  \n    Leave unchecked to keep **32-bit float** output.\n---\n\n21. **Reconstruct!** \n\n![plot](https://raw.githubusercontent.com/obandomarcos/ToMoDL/refs/heads/nhattm/napari-tomodl/figures/reconstruct_button.png)\n\n   A new layer will appear on top of the projections stack with the reconstructed volume.\n\n\n## \ud83d\udcbb Installation Guide *(No Code \u2014 Highly Recommended)*\n\n### \ud83e\udde9 **Step 1: Install Napari (Bundled App)**\n\n> \ud83d\udca1 *Skip this step if you already installed Napari via `pip`.*\n\nYou can directly download the official Napari **bundled installer** for your operating system:\n\n* \ud83e\ude9f **Windows (.exe):**\n  \ud83d\udc49 [napari-0.6.5-Windows-x86_64.exe](https://github.com/napari/napari/releases/download/v0.6.5/napari-0.6.5-Windows-x86_64.exe)\n\n* \ud83d\udc27 **Ubuntu (.sh):**\n  \ud83d\udc49 [napari-0.6.5-Linux-x86_64.sh](https://github.com/napari/napari/releases/download/v0.6.5/napari-0.6.5-Linux-x86_64.sh)\n\n\ud83d\udcd8 **Official Guide:**\nFollow the Napari documentation for detailed installation steps:\n\ud83d\udd17 [Napari Installation Guide (Bundled App)](https://napari.org/0.6.5/tutorials/fundamentals/installation_bundle_conda.html)\n\n---\n\n### \u2699\ufe0f **Step 2: Install PyTorch Inside Napari\u2019s Bundled Environment**\n\n> \ud83d\udca1 *Skip this step if PyTorch is already installed in your Napari environment.*\n\nThis step ensures **PyTorch** is properly installed within Napari\u2019s internal Conda environment for full compatibility.\n\n#### \ud83e\ude9f **Windows Users**\n\n1. Download the installer:\n   \ud83d\udd17 [install_torch2napari_windows.bat](https://github.com/obandomarcos/ToMoDL/releases/download/v.0.2.25/install_torch2napari_windows.bat)\n2. Double-click the `.bat` file to run it.\n   *(It will automatically detect Napari\u2019s environment and install PyTorch.)*\n\n#### \ud83d\udc27 **Linux Users**\n\n1. Download the installer:\n   \ud83d\udd17 [install_torch2napari_linux.sh](https://github.com/obandomarcos/ToMoDL/releases/download/v.0.2.25/install_torch2napari_linux.sh)\n2. Run it in your terminal:\n\n   ```bash\n   bash install_torch2napari_linux.sh\n   ```\n\n---\n\n### 3\ufe0f\u20e3 Install our plugin \u2014 **napari-tomodl**\n\nOur plugin is available on the [napari-hub](https://napari-hub.org/plugins/napari-tomodl.html).\n---\n\ud83d\udd39 Option 1: Install directly from napari\n1. Open **napari**.  \n2. Go to **Plugins \u2192 Install/Uninstall Plugins**.  \n3. Search for **napari-tomodl** and click **Install**.\n---\n\ud83d\udd39 Option 2: Install via pip (from Napari Console)\nOpen napari\u2019s **Python Console** and type:\n\n```bash\npip install napari-tomodl\n```\n\n> After installation, **restart napari** to apply the changes. \ud83d\ude0a\n\n## \ud83e\udd1d Contributing\n\nContributions are very welcome. Tests can be run with [tox], please ensure\nthe coverage at least stays the same before you submit a pull request.\n\n## \ud83d\udcdc License\n\nDistributed under the terms of the [MIT] license,\n\"napari-tomodl\" is free and open source software\n\n## \ud83d\udc1bIssues\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n[napari]: https://github.com/napari/napari\n[Cookiecutter]: https://github.com/audreyr/cookiecutter\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause\n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt\n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt\n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt\n[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin\n\n[QBI_radon]: https://github.com/QBioImaging/QBI_radon\n[Wall-method]: https://doi.org/10.1088/0031-9155/50/19/015\n[ToMoDL-paper]: https://doi.org/10.1038/s41598-023-47650-3\n[napari]: https://github.com/napari/napari\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Marcos Antonio Obando, Minh Nhat Trinh, David Palecek, Germ\u00e1n Mato, Teresa Correia",
    "author_email": "marcos.obando@ib.edu.ar",
    "maintainer": null,
    "maintainer_email": null,
    "license": "MIT",
    "classifier": [
      "Development Status :: 2 - Pre-Alpha",
      "Framework :: napari",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Topic :: Scientific/Engineering :: Image Processing"
    ],
    "requires_dist": [
      "magicgui",
      "qtpy",
      "scikit-image",
      "scipy",
      "qbi-radon"
    ],
    "requires_python": ">=3.10",
    "requires_external": null,
    "project_url": null,
    "provides_extra": null,
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}