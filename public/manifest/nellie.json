{
  "name": "nellie",
  "display_name": "Nellie",
  "visibility": "public",
  "icon": "",
  "categories": [],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "nellie.loader",
        "title": "Nellie",
        "python_name": "nellie_napari:NellieLoader",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": null,
    "writers": null,
    "widgets": [
      {
        "command": "nellie.loader",
        "display_name": "Nellie",
        "autogenerate": false
      }
    ],
    "sample_data": null,
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "nellie",
    "version": "0.4.1",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy",
    "description": "# Nellie\n## Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy\n\n<img src=\"https://github.com/aelefebv/nellie/assets/26515909/96b7a113-be60-4028-bcd9-b444bdb943f6\" width=\"200px\" align=\"left\" /> *arXiv* \n\n  [Preprint Link](https://arxiv.org/abs/2403.13214) | [Cite](#reference)\n\n**Abstract:** The analysis of dynamic organelles remains a formidable challenge, though key to understanding biological processes. We introduce Nellie, an automated and unbiased pipeline for segmentation, tracking, and feature extraction of diverse intracellular structures. Nellie adapts to image metadata, eliminating user input. Nellie\u2019s preprocessing pipeline enhances structural contrast on multiple intracellular scales allowing for robust hierarchical segmentation of sub-organellar regions. Internal motion capture markers are generated and tracked via a radius-adaptive pattern matching scheme, and used as guides for sub-voxel flow interpolation. Nellie extracts a plethora of features at multiple hierarchical levels for deep and customizable analysis. Nellie features a Napari-based GUI that allows for code-free operation and visualization, while its modular open-source codebase invites customization by experienced users. \n\n**Nellie's pipeline and Napari plugin are both very much in early stages,** therefore [I highly encourage any and all feedback](#getting-help).\n\n## Example output intermediates\n\nhttps://github.com/aelefebv/nellie/assets/26515909/1df8bf1b-7116-4d19-b5fb-9658f744675b\n\n## Installation (~ 1 minute)\n\n**Notes:** \n- It is recommended (but usually not required) to [create a new environment](https://docs.python.org/3/library/venv.html) for Nellie to avoid conflicts with other packages.\n- May take several minutes to install.\n- Choose one of the following methods, and only one!\n- If you do not already have Python 3.9 or higher installed, download it via the [python website]([url](https://www.python.org/downloads/)).\n\nhttps://github.com/user-attachments/assets/50b1cd4b-6df7-4f19-8db3-4dcc03388513\n\n\n### Option 1. Via Napari plugin manager:\nIf not already installed, install Napari: https://napari.org/stable/tutorials/fundamentals/installation\n\nhttps://github.com/user-attachments/assets/0d44abe5-f575-4bd4-962a-2c102faf737c\n\n\n1. Open Napari\n2. Go to ```Plugins > Install/Uninstall Plugins...```\n3. Search for Nellie and click ```Install```\n4. Make sure Nellie is updated to the latest version.\n5. Restart Napari.\n### Option 2. Via PIP:\n\n\nhttps://github.com/user-attachments/assets/b63df093-e3e1-49cb-925b-7efce36b9015\n\n\n```bash\npython3 -m pip install nellie\n```\n#### Option 2a for NVIDIA GPU acceleration, optional (Windows, Linux):\nTo use GPU acceleration via NVIDIA GPUs, you also need to install cupy:\n```bash\npip install cupy-cudaXXx\n```\n- replace ```cupy-cudaXXx``` with the [appropriate version](https://docs.cupy.dev/en/stable/install.html#installing-cupy) for your CUDA version.\n  - i.e. ```cupy-cuda11x``` for CUDA 11.x or ```cupy-cuda12x``` for CUDA 12.x\n- if you don't have CUDA installed, [go here](https://docs.cupy.dev/en/stable/install.html).\n- Mac Metal GPU-acceleration coming... eventually.\n\n## Usage\nThe sample dataset shown below is in the repo if you want to play around without, and can be downloaded [here](https://github.com/aelefebv/nellie/tree/main/sample_data).\n\n### General data preparation\n- It is strongly recommended to have your data in a parsable format, such as .ome.tif, .nd2, or other raw data files from microscopes.\n  - Importing into ImageJ/FIJI and saving via BioFormats with the proper image dimensions should do the trick.\n  - If the metadata cannot be parsed, you will have to manually enter it.\n- It is also recommended to crop your image as much as possible to reduce processing time and memory usage. But really, unless you have massive lightsheet data, it should be pretty fast (seconds to minutes on a typical modern desktop computer).\n\n### 3D + Timeseries dataset\n\nhttps://github.com/user-attachments/assets/531f76ee-f58e-4058-b5dc-4fdf09af3660\n\n### 3D (no Timeseries) dataset\n\nhttps://github.com/user-attachments/assets/30d55bfa-bade-4987-88f0-255bb36cb7e8\n\n### 2D + Timeseries dataset\n\nhttps://github.com/user-attachments/assets/d534c6e1-df31-4964-9c12-edff56228be3\n\n### Running Nellie's processing pipeline\n1. Start Napari (open a Terminal and type napari)\n    ```bash\n    napari\n    ```\n2. Go to \n```Plugins > Nellie (nellie)``` then to the ```File select``` tab.\n3. Click ```Select File``` of ```Select Folder``` to select your image(s).\n   - If the metadata boxes do not fill in automatically and turn red, this means Nellie did not detect that metadata portion from your image, and you must manually enter it or reformat your image and try again.\n     - The metadata slot will appear green if it is in the correct format.\n   - *Note, if you are batch processing, the metadata must be the same for all images if any of them are in an incorrect format (this will be fixed eventually). If they are different, but all pass validation, then it will process fine.\n   - You can preview your image via the ```Open preview``` button once the metadata is filled in to ensure it looks correct.\n   - From this tab, you can also choose what time points and channel you want to analyze, if your file contains more than one slice in those dimensions.\n4. Click the ```Process``` tab.\n5. You can run the full pipeline with ```Run Nellie```, or run individual steps below.\n    - Steps can only be run once its previous step has been run.\n    - Likewise, visualizations in the ```Visualization``` tab can only be opened once its respective step has been run.\n6. All intermediate files and output csvs will be saved to ```[image_directory]/nellie_output/```, which can be accessed via the ```Open output directory``` button.\n   - A separate .csv is created for each level of the organellar hierarchy.\n7. Once features have been exported, Nellie will automatically detect this, and allow analysis via the ```Analyze``` tab.\n   - Analysis at this point is optional, but can be helpful for visualizing, and selectively exporting data.\n\n### Using Nellie's visualization plugin\n1. Follow the previous processing steps, you only need to do this once per file as long as you don't move or delete the files.\n2. Open the ```Visualization``` tab\n3. Select a visualization from the list.\n   1. ```Raw```: Visualize the raw data for the processed channel.\n   2. ```Preprocessed```: Visualize the contrast-enhanced data.\n   3. ```Segmentation```: Visualize the organelle and branch instance segmentation masks.\n   4. ```Mocap Markers```: Visualize the mocap markers used for waypoints.\n   5. ```Reassigned Labels```: Visualize the organelle and branch instance segmentation masks where voxels are reassigned based on the first timepoint.\n4. To visualize tracks, open and select one of the segmentation layers.\n5. To visualize all tracks of all organelles/branches, click the ```Visualize all frame labels' tracks``` button.\n6. To visualize all tracks of a specific organelle/branch:\n   1. Click on the layer, and use the eyedropper tool at the top to select an organelle/branch to track.\n   2. Click the ```Visualize selected label's tracks```.\n\n### Using Nellie's analysis plugin\n1. Follow the previous processing steps, you only need to do this once per file as long as you don't move or delete the files.\n2. Open the ```Analyze``` tab, select the hierarchy level you want to visualize from the dropdown.\n3. Select the level-specific feature you want to visualize from the new dropdown.\n4. A histogram of all the data will be displayed.\n   - This histogram can be directly exported via the ```Save graph``` button. A .png will be saved to ```[image_directory]/nellie_output/graphs/``` with the current datetime.\n   - The values of the histogram can be exported via the ```Export graph data``` button. A .csv will be saved to ```[image_directory]/nellie_output/graphs/``` with the current datetime.\n   - The histogram's x-axis can be viewed in log10 scale via the ```Log scale``` checkbox.\n   - By default, the histogram shows lines at the mean +/- 1 standard deviation. This can instead be switched to median and quartiles via the ```Median view``` checkbox.\n5. Press the ```Overlay mask``` button to colormap the organelle mask based on your selected feature.\n   - Once overlaid, toggle the ```Timepoint data``` checkbox to allow you to select a specific timepoint to visualize via the slider.\n\n## Other features\n- Nellie's plugin offers an ```Easy screenshot``` feature:\n  - Press the button under ```Easy screenshot``` or hit Ctrl/Cmd-Shift-E after clicking your image.\n  - The .png will be saved to ```[image_directory]/nellie_output/screenshots/``` with the current datetime.\n\n## Feedback / Getting Help\nA few options are available for providing feedback or getting help with Nellie:\n\n[Github Issues](https://github.com/aelefebv/nellie/issues/new) | [email](mailto:austin.e.lefebvre+nellie@gmail.com) | [X](https://twitter.com/Austin_Lefebvre) | wherever else you can find me!\n\nTo avoid any unnecessary back-and-forth, please include any/all (if possible) of the following information in your bug report:\n- What kind of computer do you have, and what are its specs?\n- Send me screenshots of what is not working.\n- Send me any error logs in your terminal.\n- Send me the file you ran (if possible).\n- Any other information that might be helpful\n\n## Other Info\nFor a 16bit dataset, the output:input ratio is ~15x. There is an option in the GUI to automatically delete intermediates after processing, keeping only the CSV files containing the extracted features.\n\n## Requirements\nNellie has been tested on the following configurations:\n- Mac, Linux, and Windows operating systems\n- Python >= 3.9\n\n## License\nNellie \u00a9 2024 by [Austin E. Y. T. Lefebvre](https://github.com/aelefebv) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)\n\n## Reference\nIf you used Nelly or found this work useful in your own research, please cite our [arXiv preprint](https://arxiv.org/abs/2403.13214):\n\nLefebvre, A. E. Y. T., Sturm, G., et. al. Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy, arXiv, 2024, https://arxiv.org/abs/2403.13214\n\n```\n@misc{lefebvre2024nellie,\n      title={Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy}, \n      author={Austin E. Y. T. Lefebvre and Gabriel Sturm and Ting-Yu Lin and Emily Stoops and Magdalena Preciado Lopez and Benjamin Kaufmann-Malaga and Kayley Hake},\n      year={2024},\n      eprint={2403.13214},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n## More fun examples\n### Microtubule growing ends:\n\nhttps://github.com/aelefebv/nellie/assets/26515909/88578dc9-f5c5-4188-a0e2-4e37037a44a9\n\n### Endoplasmic reticulum:\n\nhttps://github.com/aelefebv/nellie/assets/26515909/db76d388-a9cc-4650-b93d-69d357ace418\n\n### Peroxisomes:\n\nhttps://github.com/aelefebv/nellie/assets/26515909/58bda3cb-6489-4620-8584-a3728cd6b2ec\n\n## Code contents:\nFull documentation can be found within the code, and compiled by Sphinx in the file docs/_build/html/index.html\n\n### Nellie pipeline\nAll the Nellie pipeline code is found within the nellie folder\n- File and metadata loading, and file preparation is found at nellie/im_info/verifier.py\n- Preprocessing is found at nellie/segmentation/filtering.py\n- Segmentation of organelles is found at nellie/segmentation/labelling.py\n- Skeletonization and segmentation of branches is found at nellie/segmentation/networking.py\n- Mocap marker detection is found at nellie/segmentation/mocap_marking.py\n- Mocap marker tracking is found at nellie/tracking/hu_tracking.py\n- Voxel reassignment via flow interpolation is found at nellie/tracking/voxel_reassignment.py\n- Hierarchical feature extraction is found at nellie/feature_extraction/hierarchical.py\n\n### Nellie Napari plugin\nAll the Napari plugin code is found with the nellie_napari folder\n- The home tab is found at nellie_napari/nellie_home.py\n- The file selection tab is found at nellie_napari/nellie_fileselect.py\n- The processing tab is found at nellie_napari/nellie_processor.py\n- The visualization tab is found at nellie_napari/nellie_visualizer.py\n- The analysis tab is found at nellie_napari/nellie_analysis.py\n- The settings tab is found at nellie_napari/nellie_settings.py\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": "https://github.com/aelefebv/nellie",
    "download_url": null,
    "author": "Austin E. Y. T. Lefebvre",
    "author_email": "austin.e.lefebvre+nellie@gmail.com",
    "maintainer": null,
    "maintainer_email": null,
    "license": null,
    "classifier": [
      "Framework :: napari"
    ],
    "requires_dist": [
      "numpy==1.26.4",
      "scipy==1.12.0",
      "scikit-image==0.22.0",
      "nd2==0.9.0",
      "ome-types==0.5.2",
      "pandas==2.2.1",
      "matplotlib==3.8.3",
      "napari[all]",
      "imagecodecs",
      "pydantic==2.9.2",
      "pydantic-core==2.23.4"
    ],
    "requires_python": ">=3.9",
    "requires_external": null,
    "project_url": null,
    "provides_extra": null,
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}