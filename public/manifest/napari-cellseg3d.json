{
  "name": "napari_cellseg3d",
  "display_name": "CellSeg3D",
  "visibility": "public",
  "icon": "",
  "categories": [],
  "schema_version": "0.0.4",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "napari_cellseg3d.load",
        "title": "Create reviewer",
        "python_name": "napari_cellseg3d.plugins:Reviewer",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari_cellseg3d.help",
        "title": "Create Help",
        "python_name": "napari_cellseg3d.plugins:Helper",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari_cellseg3d.utils",
        "title": "Create utilities",
        "python_name": "napari_cellseg3d.plugins:Utilities",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari_cellseg3d.infer",
        "title": "Create Inference widget",
        "python_name": "napari_cellseg3d.plugins:Inferer",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari_cellseg3d.train",
        "title": "Create Trainer widget",
        "python_name": "napari_cellseg3d.plugins:Trainer",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": null,
    "writers": null,
    "widgets": [
      {
        "command": "napari_cellseg3d.load",
        "display_name": "Labeling",
        "autogenerate": false
      },
      {
        "command": "napari_cellseg3d.infer",
        "display_name": "Inference",
        "autogenerate": false
      },
      {
        "command": "napari_cellseg3d.train",
        "display_name": "Training",
        "autogenerate": false
      },
      {
        "command": "napari_cellseg3d.utils",
        "display_name": "Utilities",
        "autogenerate": false
      },
      {
        "command": "napari_cellseg3d.help",
        "display_name": "Help/About...",
        "autogenerate": false
      }
    ],
    "sample_data": null,
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "napari_cellseg3d",
    "version": "0.2.1",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "Plugin for cell segmentation in 3D",
    "description": "# CellSeg3D: self-supervised (and supervised) 3D cell segmentation, primarily for mesoSPIM data!\n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cellseg3d)](https://www.napari-hub.org/plugins/napari-cellseg3d)\n[![PyPI](https://img.shields.io/pypi/v/napari-cellseg3d.svg?color=green)](https://pypi.org/project/napari-cellseg3d)\n[![Downloads](https://static.pepy.tech/badge/napari-cellseg3d)](https://pepy.tech/project/napari-cellseg3d)\n[![Downloads](https://static.pepy.tech/badge/napari-cellseg3d/month)](https://pepy.tech/project/napari-cellseg3d)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/AdaptiveMotorControlLab/CellSeg3D/raw/main/LICENSE)\n[![codecov](https://codecov.io/gh/AdaptiveMotorControlLab/CellSeg3D/branch/main/graph/badge.svg?token=hzUcn3XN8F)](https://codecov.io/gh/AdaptiveMotorControlLab/CellSeg3D)\n<a href=\"https://github.com/psf/black\"><img alt=\"Code style: black\" src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"></a>\n\n<img src=\"https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/838605d0-9723-4e43-83cd-6dbfe4adf36b/cellseg-logo.png?format=1500w\" title=\"cellseg3d\" alt=\"cellseg3d logo\" width=\"350\" align=\"right\" vspace = \"80\"/>\n\n\n**A package for 3D cell segmentation with deep learning, including a napari plugin**: training, inference, and data review. In particular, this project was developed for analysis of mesoSPIM-acquired (cleared tissue + lightsheet) brain tissue datasets, but is not limited to this type of data. [Check out our preprint for more information!](https://www.biorxiv.org/content/10.1101/2024.05.17.594691v1)\n\n\n![demo](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/0d16a71b-3ff2-477a-9d83-18d96cb1ce28/full_demo.gif?format=500w)\n\n\n## Installation\n\n \ud83d\udcbb See the [Installation page](https://adaptivemotorcontrollab.github.io/CellSeg3D/welcome.html) in the documentation for detailed instructions.\n\n## Documentation\n\n\ud83d\udcda Documentation is available at [https://AdaptiveMotorControlLab.github.io/CellSeg3D\n](https://adaptivemotorcontrollab.github.io/CellSeg3D/welcome.html)\nYou can also generate docs locally by running ``make html`` in the docs/ folder.\n\n## Quick Start\n\nTo use the plugin, please run:\n```\nnapari\n```\nThen go into Plugins > napari-cellseg3d, and choose which tool to use.\n\n- **Review (label)**: This module allows you to review your labels, from predictions or manual labeling, and correct them if needed. It then saves the status of each file in a csv, for easier monitoring.\n- **Inference**: This module allows you to use pre-trained segmentation algorithms on volumes to automatically label cells and compute statistics.\n- **Train**:  This module allows you to train segmentation algorithms from labeled volumes.\n- **Utilities**: This module allows you to perform several actions like cropping your volumes and labels dynamically, by selecting a fixed size volume and moving it around the image; fragment images into smaller cubes for training; or converting labels from instance to segmentation and the opposite.\n\n## Why use CellSeg3D?\n\nThe strength of our approach is we can match supervised model performance with purely self-supervised learning, meaning users don't need to spend (hundreds) of hours on annotation. Here is a quick look of our key results. TL;DR see panel **f**, which shows that with minmal input data we can outperform supervised models:\n\n<p align=\"center\">\n<img src=\"https://www.biorxiv.org/content/biorxiv/early/2024/05/17/2024.05.17.594691/F1.large.jpg?format=200w\" alt=\"Figure1\" width=\"600\"/>\n</p>\n\n#### Performance of 3D Semantic and Instance Segmentation Models.\n**a:** Raw mesoSPIM whole-brain sample, volumes and corresponding ground truth labels from somatosensory (S1) and visual (V1) cortical regions.\n**b:** Evaluation of instance segmentation performance for several supervised models over three data subsets. F1-score is computed from the Intersection over Union (IoU) with ground truth labels, then averaged. Error bars represent 50% Confidence Intervals (CIs).\n**c:** View of 3D instance labels from supervised models, as noted, for visual cortex volume in b evaluation.\n**d:** Illustration of our WNet3D architecture showcasing the dual 3D U-Net structure with modifications (see Methods).\n**e:** Example 3D instance labels from WNet3D; top row is S1, bottom is V1, with artifacts removed.\n**f:** Semantic segmentation performance: comparison of model efficiency, indicating the volume of training data required to achieve a given performance level. Each supervised model was trained with an increasing percentage of training data (with 10, 20, 60 or 80%, left to right within each model grouping); Dice score was computed on unseen test data, over three data subsets for each training/evaluation split. Our self-supervised model (WNet3D) is also trained on a subset of the training set of images, but always without human labels. Far right: We also show performance of the pretrained WNet3D available in the plugin (far right), with and without removing artifacts in the image. See Methods for details. The central box represents the interquartile range (IQR) of values with the median as a horizontal line, the upper and lower limits the upper and lower quartiles. Whiskers extend to data points within 1.5 IQR of the quartiles.\n**g:** Instance segmentation performance comparison of Swin-UNetR and WNet3D (pretrained, see Methods), evaluated on unseen data across 3 data subsets, compared with a Swin-UNetR model trained using labels from the WNet3D self-supervised model. Here, WNet3D was trained on separate data, producing semantic labels that were then used to train a supervised Swin-UNetR model, still on held-out data. This supervised model was evaluated as the other models, on 3 held-out images from our dataset, unseen during training. Error bars indicate 50% CIs.\n\n\n## News\n\n**New version: v0.2.1**\n\n- v0.2.1:\n  - Updated plugin default behaviors across the board to be more readily applicable to demo data\n  - Threshold value in inference is now automatically set by default according to performance on demo data on a per-model basis\n  - Added a grid search utility to find best thresholds for supervised models\n\n- v0.2.0:\n  - Changed project name to \"napari_cellseg3d\" to avoid setuptools deprecation\n  - Small API changes for training/inference from a script\n  - Some fixes to WandB integration and csv saving after training\n\nPrevious additions:\n\n- v0.1.2: Fixed manifest issue for PyPi\n- Improved training interface\n- Unsupervised model : WNet3D\n  - Generate labels directly from raw data!\n  - Can be trained in napari directly or in Google Colab\n  - Pretrained weights for mesoSPIM whole-brain cell segmentation\n- WandB support (install wandb and login to use automatically when training)\n- Remade and improved documentation\n  - Moved to Jupyter Book\n  - Dedicated installation page, and working ARM64 install for macOS Silicon users\n- New utilities\n- Many small improvements and many bug fixes\n\n\n\n\n## Requirements\n\n**Compatible with Python 3.8 to 3.10.**\nRequires **[napari]**, **[PyTorch]** and **[MONAI]**.\nCompatible with Windows, MacOS and Linux.\nInstallation should not take more than 30 minutes, depending on your internet connection.\n\nFor PyTorch, please see [the PyTorch website for installation instructions].\n\nA CUDA-capable GPU is not needed but very strongly recommended, especially for training.\n\nIf you get errors from MONAI regarding missing readers, please see [MONAI's optional dependencies] page for instructions on getting the readers required by your images.\n\n### Install note for ARM64 (Silicon) Mac users\n\nTo avoid issues when installing on the ARM64 architecture, please follow these steps.\n\n1) Create a new conda env using the provided conda/napari_CellSeg3D_ARM64.yml file :\n\n        git clone https://github.com/AdaptiveMotorControlLab/CellSeg3d.git\n        cd CellSeg3d\n        conda env create -f conda/napari_CellSeg3D_ARM64.yml\n        conda activate napari_CellSeg3D_ARM64\n\n\n2) Install a Qt backend (PySide or PyQt5)\n3) Launch napari, the plugin should be available in the plugins menu.\n\n\n\n## Issues\n\n**Help us make the code better by reporting issues and adding your feature requests!**\n\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n## Testing\n\nBefore testing, install all requirements using ``pip install napari-cellseg3d[test]``.\n\n``pydensecrf`` is also required for testing.\n\nTo run tests locally:\n\n- Locally : run ``pytest`` in the plugin folder\n- Locally with coverage : In the plugin folder, run ``coverage run --source=napari_cellseg3d -m pytest`` then ``coverage xml`` to generate a .xml coverage file.\n- With tox : run ``tox`` in the plugin folder (will simulate tests with several python and OS configs, requires substantial storage space)\n\n## Contributing\n\nContributions are very welcome.\n\nPlease ensure the coverage at least stays the same before you submit a pull request.\n\nFor local installation from Github cloning, please run:\n\n```\npip install -e .\n```\n\n## License\n\nDistributed under the terms of the [MIT] license.\n\n\"napari-cellseg3d\" is free and open source software.\n\n[napari-hub]: https://www.napari-hub.org/plugins/napari-cellseg3d\n\n[file an issue]: https://github.com/AdaptiveMotorControlLab/CellSeg3D/issues\n[napari]: https://github.com/napari/napari\n[Cookiecutter]: https://github.com/audreyr/cookiecutter\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n[Installation page]: https://adaptivemotorcontrollab.github.io/CellSeg3D/source/guides/installation_guide.html\n[the PyTorch website for installation instructions]: https://pytorch.org/get-started/locally/\n[PyTorch]: https://pytorch.org/get-started/locally/\n[MONAI's optional dependencies]: https://docs.monai.io/en/stable/installation.html#installing-the-recommended-dependencies\n[MONAI]: https://docs.monai.io/en/stable/installation.html#installing-the-recommended-dependencies\n\n## Citation\n\n```\n@article {Achard2024,\n\tauthor = {Achard, Cyril and Kousi, Timokleia and Frey, Markus and Vidal, Maxime and Paychere, Yves and Hofmann, Colin and Iqbal, Asim and Hausmann, Sebastien B. and Pages, Stephane and Mathis, Mackenzie W.},\n\ttitle = {CellSeg3D: self-supervised 3D cell segmentation for microscopy},\n\telocation-id = {2024.05.17.594691},\n\tyear = {2024},\n\tdoi = {10.1101/2024.05.17.594691},\n\tpublisher = {Cold Spring Harbor Laboratory},\n\tURL = {https://www.biorxiv.org/content/early/2024/05/17/2024.05.17.594691},\n\teprint = {https://www.biorxiv.org/content/early/2024/05/17/2024.05.17.594691.full.pdf},\n\tjournal = {bioRxiv}\n}\n```\n## Acknowledgements\n\nThis plugin was developed by originally Cyril Achard, Maxime Vidal, Mackenzie Mathis.\nThis work was funded, in part, from the Wyss Center to the [Mathis Laboratory of Adaptive Intelligence](https://www.mackenziemathislab.org/).\nPlease refer to the documentation for full acknowledgements.\n\n## Plugin base\n\nThis [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": null,
    "author_email": "Cyril Achard <cyril.achard@epfl.ch>, Maxime Vidal <maxime.vidal@epfl.ch>, Mackenzie Mathis <mackenzie@post.harvard.edu>",
    "maintainer": null,
    "maintainer_email": null,
    "license": "MIT",
    "classifier": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "Framework :: napari",
      "Topic :: Software Development :: Testing",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: 3.10",
      "Operating System :: OS Independent",
      "License :: OSI Approved :: MIT License",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Image Processing",
      "Topic :: Scientific/Engineering :: Visualization"
    ],
    "requires_dist": [
      "numpy",
      "napari[all]>=0.4.14",
      "QtPy",
      "scikit-image>=0.19.2",
      "matplotlib>=3.4.1",
      "tifffile>=2022.2.9",
      "imagecodecs>=2023.3.16",
      "torch>=1.11",
      "monai[einops,nibabel]>=0.9.0",
      "itk",
      "tqdm",
      "pyclesperanto-prototype",
      "tqdm",
      "matplotlib",
      "pyqt5; extra == \"pyqt5\"",
      "pyside2; extra == \"pyside2\"",
      "pyside6; extra == \"pyside6\"",
      "onnx; extra == \"onnx-cpu\"",
      "onnxruntime; extra == \"onnx-cpu\"",
      "onnx; extra == \"onnx-gpu\"",
      "onnxruntime-gpu; extra == \"onnx-gpu\"",
      "wandb; extra == \"wandb\"",
      "isort; extra == \"dev\"",
      "black; extra == \"dev\"",
      "ruff; extra == \"dev\"",
      "pre-commit; extra == \"dev\"",
      "tuna; extra == \"dev\"",
      "twine; extra == \"dev\"",
      "jupyter-book; extra == \"docs\"",
      "pytest; extra == \"test\"",
      "pytest_qt; extra == \"test\"",
      "pytest-cov; extra == \"test\"",
      "coverage; extra == \"test\"",
      "tox; extra == \"test\"",
      "twine; extra == \"test\"",
      "onnx; extra == \"test\"",
      "onnxruntime; extra == \"test\""
    ],
    "requires_python": ">=3.8",
    "requires_external": null,
    "project_url": [
      "Homepage, https://github.com/AdaptiveMotorControlLab/CellSeg3D",
      "Documentation, https://adaptivemotorcontrollab.github.io/cellseg3d-docs/res/welcome.html",
      "Issues, https://github.com/AdaptiveMotorControlLab/CellSeg3D/issues"
    ],
    "provides_extra": [
      "crf",
      "pyqt5",
      "pyside2",
      "pyside6",
      "onnx-cpu",
      "onnx-gpu",
      "wandb",
      "dev",
      "docs",
      "test"
    ],
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}