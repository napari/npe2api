{
  "name": "ebi_oct",
  "display_name": "ebi_oct",
  "visibility": "public",
  "icon": "",
  "categories": [],
  "schema_version": "0.2.1",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "ebi_oct.widgets",
        "title": "OCT Processing Widgets",
        "python_name": "ebi_oct.napari_plugin:main",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": null,
    "writers": null,
    "widgets": [
      {
        "command": "ebi_oct.widgets",
        "display_name": "OCTool",
        "autogenerate": false
      }
    ],
    "sample_data": null,
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.4",
    "name": "ebi_oct",
    "version": "1.1.0",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "A package for analyzing optical coherence tomography (OCT) images for biofilm.",
    "description": "# oct_analysis\n\noct_analysis is a Python library for the processing of image data for optical methods (foremost optical coherence tomography (OCT)).\n\n## Installation\n\n```bash\npip install oct_analysis\n```\n\n## Features\n\nThe oct_analysis python package includes various functions for:\n\n- Unpacking *.oct files and loading tiff files as numpy array\n- Preprocessing functions to identify and remove objects/boundaries\n- Image segmentation and binarization\n- Post-processing funtions for the calcuation and saving of structural parameters from the imaging stacks\n\n## Usage\nThe documentation can be found in https://oct-analysis.readthedocs.io/en/latest/index.html\n\nExamples for the usage of the functions are described in https://github.com/AndreasNetsch/oct_analysis/tree/main/examples\n\n```python\nfrom oct_analysis import (\n    read_tiff,\n    select_tiff_folder,\n    convert_to_8bit,\n    find_substratum,\n    voxel_count,\n    find_max_zero,\n    untilt,\n    generate_Height_Map\n)\n```\n\n## Collaboration and Development\n\n### Setup\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/AndreasNetsch/oct_analysis.git\ncd oct_analysis\n```\n\n2. Create a virtual environment and install development dependencies:\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -e \".[dev]\"\n```\n\n### Testing\n\nRun tests with pytest:\n\n```bash\npytest\n```\n\n### Code Formatting and Linting\n\nThis project uses pre-commit hooks to ensure code quality. After installing the development dependencies, set up the pre-commit hooks:\n\n```bash\npre-commit install\n```\n\nThis will automatically format your code with Black and check it with Flake8 before each commit. You can also run the hooks manually:\n\n```bash\npre-commit run --all-files\n```\n\n### Building the package\n\n```bash\npython -m build\n```\n\n### Documentation\n\nThis project uses Sphinx for documentation. To build the documentation locally:\n\n```bash\ncd docs\nmake html\n```\n\nThe generated documentation will be available in `docs/build/html/index.html`.\n\n#### ReadTheDocs Integration\n\nThe documentation is also configured to be built automatically on [ReadTheDocs](https://readthedocs.org/). To set it up:\n\n1. Push your code to GitHub\n2. Sign up for a ReadTheDocs account\n3. Import your repository on ReadTheDocs\n4. ReadTheDocs will automatically build and host the documentation\n\nYou can customize the build process by modifying `.readthedocs.yml` and the Sphinx configuration files in the `docs` directory.\n\n## CI/CD\n\nThis project uses GitHub Actions for:\n\n- Running tests on multiple Python versions\n- Linting the code\n- Building and publishing the package to PyPI when a new version tag is pushed\n\n### Creating Releases\n\nThe CI/CD pipeline is configured to automatically build and publish the package to PyPI when a new version tag is pushed to the repository. This process ensures that only properly versioned, tagged releases get published.\n\nTo create and publish a new release:\n\n1. Update the version number in `setup.py`\n2. Commit your changes:\n   ```bash\n   git add setup.py\n   git commit -m \"Bump version to x.y.z\"\n   ```\n3. Create a new version tag (tag name must start with \"v\"):\n   ```bash\n   git tag vx.y.z\n   ```\n4. Push the tag to GitHub:\n   ```bash\n   git push origin vx.y.z\n   ```\n\nOnce the tag is pushed, GitHub Actions will:\n\n1. Run all tests on multiple Python versions\n2. If tests pass, build the package\n3. Publish the package to PyPI using the configured PyPI API token\n\nNote: Make sure you've added a `PYPI_API_TOKEN` secret to your GitHub repository settings under \"Settings > Secrets and Variables > Actions\" before triggering a release.\n\n## License\n\nMIT License\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": null,
    "author_email": "Andreas Netsch <andreas.netsch@partner.kit.edu>, Jonas Ullmann <ullmann@dvgw-ebi.de>",
    "maintainer": null,
    "maintainer_email": null,
    "license": "MIT",
    "classifier": [
      "Framework :: napari"
    ],
    "requires_dist": [
      "customtkinter>=5.2.0",
      "magicgui>=0.9.2",
      "matplotlib>=3.4.0",
      "napari>=0.6.1",
      "nibabel>=5.3.2",
      "numpy>=1.20.0",
      "opencv-python>=4.5.0",
      "pyqt6>=6.9.1",
      "qtpy>=2.4.0",
      "scikit-image>=0.21.0",
      "scipy>=1.13.0",
      "tifffile>=2020.6.3",
      "pre-commit==4.2.0; extra == 'dev'",
      "pytest==8.4.0; extra == 'dev'",
      "ruff==0.12.0; extra == 'dev'",
      "sphinx-autodoc-typehints==3.2.0; extra == 'dev'",
      "sphinx-rtd-theme==3.0.2; extra == 'dev'",
      "sphinx==8.2.3; extra == 'dev'",
      "uv==0.6.0; extra == 'dev'"
    ],
    "requires_python": ">=3.11",
    "requires_external": null,
    "project_url": null,
    "provides_extra": [
      "dev"
    ],
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}